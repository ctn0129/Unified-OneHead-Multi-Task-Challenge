{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e19cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting balanced multi-task learning...\n",
      "All random seeds set to: 42\n",
      "CUDA available: NVIDIA GeForce RTX 4070 SUPER\n",
      "\n",
      "==================================================\n",
      "Testing Model Architecture\n",
      "==================================================\n",
      "Testing balanced model architecture...\n",
      "Initializing multi-task model...\n",
      "Using pre-trained EfficientNet-B0\n",
      "Total parameters: 6.41M\n",
      "Parameter count within limit: 6.41M < 8M\n",
      "Input shape: torch.Size([4, 3, 224, 224])\n",
      "Detection output shape: torch.Size([4, 80])\n",
      "Segmentation output shape: torch.Size([4, 1, 224, 224])\n",
      "Classification output shape: torch.Size([4, 1000])\n",
      "Balanced model architecture test completed!\n",
      "\n",
      "==================================================\n",
      "Creating Data Loaders\n",
      "==================================================\n",
      "Checking dataset paths...\n",
      "Found VOC JSON: ./VOC_subset/train_list.json\n",
      "Successfully loaded VOC data: 240 samples\n",
      "Successfully loaded VOC data: 240 samples\n",
      "Found COCO training set: ./coco_subset/COCO_train.json and ./coco_subset/train\n",
      "✅ Successfully loaded COCO data: ./coco_subset/COCO_train.json\n",
      "Found 240 images and 793 annotations\n",
      "Number of categories: 10\n",
      "Found COCO validation set: ./coco_subset/COCO_val.json and ./coco_subset/val\n",
      "✅ Successfully loaded COCO data: ./coco_subset/COCO_val.json\n",
      "Found 60 images and 167 annotations\n",
      "Number of categories: 10\n",
      "Found ImageNet training set: ./imagenetv2_subset/imagenetv2_train.txt and ./imagenetv2_subset/imagenetv2\n",
      "Successfully loaded ImageNet data: 240 samples\n",
      "Found ImageNet validation set: ./imagenetv2_subset/imagenetv2_val.txt and ./imagenetv2_subset/imagenetv2\n",
      "Successfully loaded ImageNet data: 60 samples\n",
      "All data loaders created successfully!\n",
      "\n",
      "==================================================\n",
      "Testing Data Loading\n",
      "==================================================\n",
      "Testing single batch loading...\n",
      "Testing VOC loader...\n",
      "VOC batch loaded successfully: torch.Size([8, 3, 224, 224]), torch.Size([8, 1, 224, 224])\n",
      "Testing COCO loader...\n",
      "COCO batch loaded successfully: torch.Size([8, 3, 224, 224]), torch.Size([8, 80])\n",
      "COCO target range: [0.00, 1.00]\n",
      "COCO target type: torch.float32\n",
      "Testing ImageNet loader...\n",
      "ImageNet batch loaded successfully: torch.Size([8, 3, 224, 224]), torch.Size([8])\n",
      "\n",
      "==================================================\n",
      "Initializing Model\n",
      "==================================================\n",
      "Initializing multi-task model...\n",
      "Using pre-trained EfficientNet-B0\n",
      "Total parameters: 6.41M\n",
      "Parameter count within limit: 6.41M < 8M\n",
      "\n",
      "==================================================\n",
      "Initializing Learner\n",
      "==================================================\n",
      "Balanced continual learner initialized\n",
      "Balanced continual learner initialization completed\n",
      "\n",
      "==================================================\n",
      "Stage 1: VOC Segmentation Training\n",
      "==================================================\n",
      "\n",
      "=== Training Stage: VOC segmentation ===\n",
      "Task type: segmentation\n",
      "Set 20 epochs, early stopping patience: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 30/30 [00:04<00:00,  6.94it/s, Loss=1.4523, Metric=0.1931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2104\n",
      "Epoch 1: Loss=1.4523, Train metric=0.1931, Val metric=0.2104\n",
      "New best segmentation metric: 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 30/30 [00:02<00:00, 10.45it/s, Loss=1.3556, Metric=0.2403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2203\n",
      "Epoch 2: Loss=1.3556, Train metric=0.2403, Val metric=0.2203\n",
      "New best segmentation metric: 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 30/30 [00:02<00:00, 10.14it/s, Loss=1.2770, Metric=0.2702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2022\n",
      "Epoch 3: Loss=1.2770, Train metric=0.2702, Val metric=0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 30/30 [00:03<00:00,  9.77it/s, Loss=1.2408, Metric=0.2694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1885\n",
      "Epoch 4: Loss=1.2408, Train metric=0.2694, Val metric=0.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 30/30 [00:03<00:00,  9.92it/s, Loss=1.2094, Metric=0.2737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1964\n",
      "Epoch 5: Loss=1.2094, Train metric=0.2737, Val metric=0.1964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 30/30 [00:02<00:00, 10.05it/s, Loss=1.1742, Metric=0.2888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1945\n",
      "Epoch 6: Loss=1.1742, Train metric=0.2888, Val metric=0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 30/30 [00:02<00:00, 10.27it/s, Loss=1.1597, Metric=0.2869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1905\n",
      "Epoch 7: Loss=1.1597, Train metric=0.2869, Val metric=0.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 30/30 [00:03<00:00,  9.95it/s, Loss=1.1332, Metric=0.2932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1783\n",
      "Epoch 8: Loss=1.1332, Train metric=0.2932, Val metric=0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 30/30 [00:03<00:00,  9.60it/s, Loss=1.1133, Metric=0.2982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2063\n",
      "Epoch 9: Loss=1.1133, Train metric=0.2982, Val metric=0.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 30/30 [00:03<00:00,  9.76it/s, Loss=1.0933, Metric=0.2969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.1818\n",
      "Epoch 10: Loss=1.0933, Train metric=0.2969, Val metric=0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 30/30 [00:03<00:00,  9.64it/s, Loss=1.0823, Metric=0.2963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2004\n",
      "Epoch 11: Loss=1.0823, Train metric=0.2963, Val metric=0.2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 30/30 [00:03<00:00,  9.70it/s, Loss=1.0682, Metric=0.2950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2006\n",
      "Epoch 12: Loss=1.0682, Train metric=0.2950, Val metric=0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 30/30 [00:02<00:00, 10.24it/s, Loss=1.0503, Metric=0.3069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2002\n",
      "Epoch 13: Loss=1.0503, Train metric=0.3069, Val metric=0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 30/30 [00:02<00:00, 10.25it/s, Loss=1.0356, Metric=0.3117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation evaluation: Average IoU = 0.2032\n",
      "Epoch 14: Loss=1.0356, Train metric=0.3117, Val metric=0.2032\n",
      "Early stopping at epoch 14\n",
      "Restored best model state\n",
      "Saved task snapshot: VOC segmentation, metric: 0.2203\n",
      "Computing Fisher information for EWC...\n",
      "Computing Fisher Information Matrix, task type: segmentation\n",
      "Fisher computation completed, processed 30 batches\n",
      "EWC initialized successfully, task 1\n",
      "VOC segmentation baseline mIoU: 0.2203\n",
      "\n",
      "--- Evaluation after Stage 1 ---\n",
      "\n",
      "=== Evaluating All Tasks ===\n",
      "Segmentation evaluation: Average IoU = 0.2203\n",
      "VOC segmentation mIoU: 22.03%\n",
      "mAP computation: 10 valid classes, average AP: 0.2329\n",
      "Detection evaluation: mAP = 0.2329\n",
      "COCO detection mAP: 23.29%\n",
      "Classification evaluation: 0/60 correct, accuracy: 0.00%\n",
      "ImageNet classification Top-1: 0.00%\n",
      "\n",
      "==================================================\n",
      "Stage 2: COCO Detection Training\n",
      "==================================================\n",
      "\n",
      "=== Training Stage: COCO detection ===\n",
      "Task type: detection\n",
      "Set 25 epochs, early stopping patience: 15\n",
      "Adjusted learning rate to: 0.00017186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 30/30 [00:05<00:00,  5.73it/s, Loss=0.3265, Metric=0.7055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.3356\n",
      "Detection evaluation: mAP = 0.3356\n",
      "Epoch 1: Loss=0.3265, Train metric=0.7055, Val metric=0.3356\n",
      "New best detection metric: 0.3356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 30/30 [00:05<00:00,  5.89it/s, Loss=0.2128, Metric=0.9319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.5085\n",
      "Detection evaluation: mAP = 0.5085\n",
      "Epoch 2: Loss=0.2128, Train metric=0.9319, Val metric=0.5085\n",
      "New best detection metric: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 30/30 [00:05<00:00,  5.95it/s, Loss=0.1513, Metric=0.9785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.6232\n",
      "Detection evaluation: mAP = 0.6232\n",
      "Epoch 3: Loss=0.1513, Train metric=0.9785, Val metric=0.6232\n",
      "New best detection metric: 0.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Loss=0.1157, Metric=0.9855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.6921\n",
      "Detection evaluation: mAP = 0.6921\n",
      "Epoch 4: Loss=0.1157, Train metric=0.9855, Val metric=0.6921\n",
      "New best detection metric: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 30/30 [00:04<00:00,  6.08it/s, Loss=0.0931, Metric=0.9882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.7094\n",
      "Detection evaluation: mAP = 0.7094\n",
      "Epoch 5: Loss=0.0931, Train metric=0.9882, Val metric=0.7094\n",
      "New best detection metric: 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 30/30 [00:05<00:00,  5.84it/s, Loss=0.0777, Metric=0.9881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.7432\n",
      "Detection evaluation: mAP = 0.7432\n",
      "Epoch 6: Loss=0.0777, Train metric=0.9881, Val metric=0.7432\n",
      "New best detection metric: 0.7432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 30/30 [00:04<00:00,  6.08it/s, Loss=0.0670, Metric=0.9891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.7635\n",
      "Detection evaluation: mAP = 0.7635\n",
      "Epoch 7: Loss=0.0670, Train metric=0.9891, Val metric=0.7635\n",
      "New best detection metric: 0.7635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Loss=0.0604, Metric=0.9887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.7792\n",
      "Detection evaluation: mAP = 0.7792\n",
      "Epoch 8: Loss=0.0604, Train metric=0.9887, Val metric=0.7792\n",
      "New best detection metric: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 30/30 [00:05<00:00,  5.97it/s, Loss=0.0530, Metric=0.9900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8010\n",
      "Detection evaluation: mAP = 0.8010\n",
      "Epoch 9: Loss=0.0530, Train metric=0.9900, Val metric=0.8010\n",
      "New best detection metric: 0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 30/30 [00:04<00:00,  6.27it/s, Loss=0.0490, Metric=0.9906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8023\n",
      "Detection evaluation: mAP = 0.8023\n",
      "Epoch 10: Loss=0.0490, Train metric=0.9906, Val metric=0.8023\n",
      "New best detection metric: 0.8023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Loss=0.0442, Metric=0.9915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8060\n",
      "Detection evaluation: mAP = 0.8060\n",
      "Epoch 11: Loss=0.0442, Train metric=0.9915, Val metric=0.8060\n",
      "New best detection metric: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 30/30 [00:05<00:00,  5.83it/s, Loss=0.0408, Metric=0.9916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8102\n",
      "Detection evaluation: mAP = 0.8102\n",
      "Epoch 12: Loss=0.0408, Train metric=0.9916, Val metric=0.8102\n",
      "New best detection metric: 0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Loss=0.0373, Metric=0.9930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.7978\n",
      "Detection evaluation: mAP = 0.7978\n",
      "Epoch 13: Loss=0.0373, Train metric=0.9930, Val metric=0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 30/30 [00:05<00:00,  5.86it/s, Loss=0.0350, Metric=0.9932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8189\n",
      "Detection evaluation: mAP = 0.8189\n",
      "Epoch 14: Loss=0.0350, Train metric=0.9932, Val metric=0.8189\n",
      "New best detection metric: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 30/30 [00:05<00:00,  5.64it/s, Loss=0.0330, Metric=0.9938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8169\n",
      "Detection evaluation: mAP = 0.8169\n",
      "Epoch 15: Loss=0.0330, Train metric=0.9938, Val metric=0.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 30/30 [00:05<00:00,  5.91it/s, Loss=0.0316, Metric=0.9940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8189\n",
      "Detection evaluation: mAP = 0.8189\n",
      "Epoch 16: Loss=0.0316, Train metric=0.9940, Val metric=0.8189\n",
      "New best detection metric: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 30/30 [00:05<00:00,  5.50it/s, Loss=0.0301, Metric=0.9938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8027\n",
      "Detection evaluation: mAP = 0.8027\n",
      "Epoch 17: Loss=0.0301, Train metric=0.9938, Val metric=0.8027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 30/30 [00:05<00:00,  5.64it/s, Loss=0.0286, Metric=0.9950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8112\n",
      "Detection evaluation: mAP = 0.8112\n",
      "Epoch 18: Loss=0.0286, Train metric=0.9950, Val metric=0.8112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 30/30 [00:05<00:00,  5.64it/s, Loss=0.0283, Metric=0.9942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8309\n",
      "Detection evaluation: mAP = 0.8309\n",
      "Epoch 19: Loss=0.0283, Train metric=0.9942, Val metric=0.8309\n",
      "New best detection metric: 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 30/30 [00:05<00:00,  5.61it/s, Loss=0.0271, Metric=0.9947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8289\n",
      "Detection evaluation: mAP = 0.8289\n",
      "Epoch 20: Loss=0.0271, Train metric=0.9947, Val metric=0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 30/30 [00:04<00:00,  6.23it/s, Loss=0.0266, Metric=0.9947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8217\n",
      "Detection evaluation: mAP = 0.8217\n",
      "Epoch 21: Loss=0.0266, Train metric=0.9947, Val metric=0.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 30/30 [00:05<00:00,  5.78it/s, Loss=0.0247, Metric=0.9953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8236\n",
      "Detection evaluation: mAP = 0.8236\n",
      "Epoch 22: Loss=0.0247, Train metric=0.9953, Val metric=0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 30/30 [00:05<00:00,  5.50it/s, Loss=0.0242, Metric=0.9959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8174\n",
      "Detection evaluation: mAP = 0.8174\n",
      "Epoch 23: Loss=0.0242, Train metric=0.9959, Val metric=0.8174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 30/30 [00:05<00:00,  5.53it/s, Loss=0.0245, Metric=0.9951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8111\n",
      "Detection evaluation: mAP = 0.8111\n",
      "Epoch 24: Loss=0.0245, Train metric=0.9951, Val metric=0.8111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 30/30 [00:05<00:00,  5.56it/s, Loss=0.0245, Metric=0.9947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP computation: 10 valid classes, average AP: 0.8190\n",
      "Detection evaluation: mAP = 0.8190\n",
      "Epoch 25: Loss=0.0245, Train metric=0.9947, Val metric=0.8190\n",
      "Restored best model state\n",
      "Saved task snapshot: COCO detection, metric: 0.8309\n",
      "Computing Fisher information for EWC...\n",
      "Computing Fisher Information Matrix, task type: detection\n",
      "Fisher computation completed, processed 30 batches\n",
      "EWC initialized successfully, task 2\n",
      "COCO detection baseline mAP: 0.8309\n",
      "\n",
      "--- Evaluation after Stage 2 ---\n",
      "\n",
      "=== Evaluating All Tasks ===\n",
      "Segmentation evaluation: Average IoU = 0.2083\n",
      "VOC segmentation mIoU: 20.83%\n",
      "mAP computation: 10 valid classes, average AP: 0.8309\n",
      "Detection evaluation: mAP = 0.8309\n",
      "COCO detection mAP: 83.09%\n",
      "Classification evaluation: 0/60 correct, accuracy: 0.00%\n",
      "ImageNet classification Top-1: 0.00%\n",
      "\n",
      "==================================================\n",
      "Stage 3: ImageNet Classification Training\n",
      "==================================================\n",
      "\n",
      "=== Training Stage: ImageNet classification ===\n",
      "Task type: classification\n",
      "Set 20 epochs, early stopping patience: 10\n",
      "Adjusted learning rate to: 0.00006236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 30/30 [00:07<00:00,  4.13it/s, Loss=6.4276, Metric=0.1042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 38/60 correct, accuracy: 63.33%\n",
      "Epoch 1: Loss=6.4276, Train metric=0.1042, Val metric=63.3333\n",
      "New best classification metric: 63.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 30/30 [00:06<00:00,  4.35it/s, Loss=4.8741, Metric=0.8125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 43/60 correct, accuracy: 71.67%\n",
      "Epoch 2: Loss=4.8741, Train metric=0.8125, Val metric=71.6667\n",
      "New best classification metric: 71.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 30/30 [00:06<00:00,  4.53it/s, Loss=3.6721, Metric=0.9417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 41/60 correct, accuracy: 68.33%\n",
      "Epoch 3: Loss=3.6721, Train metric=0.9417, Val metric=68.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 30/30 [00:06<00:00,  4.53it/s, Loss=2.7331, Metric=0.9458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 49/60 correct, accuracy: 81.67%\n",
      "Epoch 4: Loss=2.7331, Train metric=0.9458, Val metric=81.6667\n",
      "New best classification metric: 81.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 30/30 [00:06<00:00,  4.54it/s, Loss=2.0712, Metric=0.9667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 52/60 correct, accuracy: 86.67%\n",
      "Epoch 5: Loss=2.0712, Train metric=0.9667, Val metric=86.6667\n",
      "New best classification metric: 86.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 30/30 [00:06<00:00,  4.48it/s, Loss=1.5677, Metric=0.9750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 59/60 correct, accuracy: 98.33%\n",
      "Epoch 6: Loss=1.5677, Train metric=0.9750, Val metric=98.3333\n",
      "New best classification metric: 98.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 30/30 [00:06<00:00,  4.48it/s, Loss=1.1665, Metric=0.9875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 59/60 correct, accuracy: 98.33%\n",
      "Epoch 7: Loss=1.1665, Train metric=0.9875, Val metric=98.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 30/30 [00:06<00:00,  4.50it/s, Loss=0.9596, Metric=0.9958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 8: Loss=0.9596, Train metric=0.9958, Val metric=100.0000\n",
      "New best classification metric: 100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 30/30 [00:06<00:00,  4.46it/s, Loss=0.8171, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 58/60 correct, accuracy: 96.67%\n",
      "Epoch 9: Loss=0.8171, Train metric=1.0000, Val metric=96.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 30/30 [00:06<00:00,  4.47it/s, Loss=0.6801, Metric=0.9917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 10: Loss=0.6801, Train metric=0.9917, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 30/30 [00:06<00:00,  4.54it/s, Loss=0.5434, Metric=0.9958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 11: Loss=0.5434, Train metric=0.9958, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 30/30 [00:06<00:00,  4.53it/s, Loss=0.4850, Metric=0.9958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 12: Loss=0.4850, Train metric=0.9958, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 30/30 [00:06<00:00,  4.54it/s, Loss=0.4315, Metric=0.9958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 13: Loss=0.4315, Train metric=0.9958, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 30/30 [00:06<00:00,  4.41it/s, Loss=0.4052, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 14: Loss=0.4052, Train metric=1.0000, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 30/30 [00:06<00:00,  4.34it/s, Loss=0.3754, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 15: Loss=0.3754, Train metric=1.0000, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 30/30 [00:07<00:00,  4.25it/s, Loss=0.3516, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 16: Loss=0.3516, Train metric=1.0000, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 30/30 [00:06<00:00,  4.46it/s, Loss=0.3282, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 17: Loss=0.3282, Train metric=1.0000, Val metric=100.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 30/30 [00:06<00:00,  4.75it/s, Loss=0.3300, Metric=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "Epoch 18: Loss=0.3300, Train metric=1.0000, Val metric=100.0000\n",
      "Early stopping at epoch 18\n",
      "Restored best model state\n",
      "Saved task snapshot: ImageNet classification, metric: 100.0000\n",
      "Computing Fisher information for EWC...\n",
      "Classification task EWC importance set to: 1600\n",
      "Computing Fisher Information Matrix, task type: classification\n",
      "Fisher computation completed, processed 30 batches\n",
      "EWC initialized successfully, task 3\n",
      "ImageNet classification baseline Top-1: 100.0000\n",
      "\n",
      "--- Evaluation after Stage 3 (before fine-tuning) ---\n",
      "\n",
      "=== Evaluating All Tasks ===\n",
      "Segmentation evaluation: Average IoU = 0.2022\n",
      "VOC segmentation mIoU: 20.22%\n",
      "mAP computation: 10 valid classes, average AP: 0.7957\n",
      "Detection evaluation: mAP = 0.7957\n",
      "COCO detection mAP: 79.57%\n",
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "ImageNet classification Top-1: 100.00%\n",
      "\n",
      "Target metrics (baseline - 5%):\n",
      "mIoU: ≥ 17.03%\n",
      "mAP: ≥ 78.09%\n",
      "Top-1: ≥ 95.00%\n",
      "All metrics meet target standards. No fine-tuning needed.\n",
      "\n",
      "==================================================\n",
      "Final Results\n",
      "==================================================\n",
      "\n",
      "=== Evaluating All Tasks ===\n",
      "Segmentation evaluation: Average IoU = 0.2022\n",
      "VOC segmentation mIoU: 20.22%\n",
      "mAP computation: 10 valid classes, average AP: 0.7957\n",
      "Detection evaluation: mAP = 0.7957\n",
      "COCO detection mAP: 79.57%\n",
      "Classification evaluation: 60/60 correct, accuracy: 100.00%\n",
      "ImageNet classification Top-1: 100.00%\n",
      "\n",
      "Forgetting criterion check:\n",
      "mIoU: 20.22% (≥ 17.03%) - Passed\n",
      "mAP: 79.57% (≥ 78.09%) - Passed\n",
      "Top-1: 100.00% (≥ 95.00%) - Passed\n",
      "\n",
      "Forgetting criterion satisfied: Yes\n",
      "\n",
      "Detailed performance analysis:\n",
      "VOC mIoU: 20.22% (baseline: 22.03%, change: -1.81%)\n",
      "COCO mAP: 79.57% (baseline: 83.09%, change: -3.52%)\n",
      "ImageNet Top-1: 100.00% (baseline: 100.00%, change: +0.00%)\n",
      "\n",
      "Training history:\n",
      "VOC segmentation: mIoU=22.03%, mAP=0.00%, Top1=0.00%\n",
      "COCO detection: mIoU=0.00%, mAP=83.09%, Top1=0.00%\n",
      "ImageNet classification: mIoU=0.00%, mAP=0.00%, Top1=100.00%\n",
      "\n",
      "Success criteria:\n",
      "mIoU ≥ 17.03%: Passed\n",
      "mAP ≥ 78.09%: Passed\n",
      "Top-1 ≥ 95.00%: Passed\n",
      "\n",
      "Overall success: Passed\n",
      "\n",
      "Performance comparison:\n",
      "Metric          Stage1     Stage2     Stage3     Final      Change    \n",
      "----------------------------------------------------------------------\n",
      "mIoU (%)        22.03      20.83      20.22      20.22      -1.81     \n",
      "mAP (%)         23.29      83.09      79.57      79.57      -3.52     \n",
      "Top-1 (%)       0.00       0.00       100.00     100.00     +0.00     \n",
      "\n",
      "Plotting training results...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss curves saved to: balanced_training_losses.png\n",
      "Loss curves saved successfully\n",
      "Training completed successfully!\n",
      "\n",
      "Final summary:\n",
      "mIoU: 20.22%\n",
      "mAP: 79.57%\n",
      "Top-1: 100.00%\n",
      "Overall success: Passed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import traceback\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Fix all random seeds\n",
    "def set_random_seed(seed=42):\n",
    "    \"\"\"Set all random seeds to ensure reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Fix Python hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"All random seeds set to: {seed}\")\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    \"\"\"COCO Detection Dataset\"\"\"\n",
    "    def __init__(self, json_file, img_dir, transform=None):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                self.data = json.load(f)\n",
    "            print(f\"✅ Successfully loaded COCO data: {json_file}\")\n",
    "            \n",
    "            self.images = self.data['images']\n",
    "            self.annotations = self.data.get('annotations', [])\n",
    "            \n",
    "            # Process categories\n",
    "            self.categories = self.data.get('categories', [])\n",
    "            self.cat_id_to_idx = {}\n",
    "            for idx, cat in enumerate(self.categories):\n",
    "                self.cat_id_to_idx[cat['id']] = idx\n",
    "            \n",
    "            # Build image to annotation mapping\n",
    "            self.img_to_anns = defaultdict(list)\n",
    "            for ann in self.annotations:\n",
    "                self.img_to_anns[ann['image_id']].append(ann)\n",
    "            \n",
    "            print(f\"Found {len(self.images)} images and {len(self.annotations)} annotations\")\n",
    "            print(f\"Number of categories: {len(self.categories)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading COCO JSON file {json_file}: {e}\")\n",
    "            # Create dummy data\n",
    "            self.images = [{'id': i, 'file_name': f'dummy_{i}.jpg'} for i in range(50)]\n",
    "            self.annotations = []\n",
    "            self.img_to_anns = defaultdict(list)\n",
    "            self.categories = [{'id': i, 'name': f'class_{i}'} for i in range(80)]\n",
    "            self.cat_id_to_idx = {i: i for i in range(80)}\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_info = self.images[idx]\n",
    "            img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "            \n",
    "            # Load image\n",
    "            if not os.path.exists(img_path):\n",
    "                # Create fixed dummy image instead of random image\n",
    "                image = Image.new('RGB', (224, 224), color=(128, 128, 128))\n",
    "            else:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Get annotations for this image\n",
    "            img_id = img_info['id']\n",
    "            anns = self.img_to_anns[img_id]\n",
    "            \n",
    "            # Create multi-label target\n",
    "            target = torch.zeros(80)\n",
    "            \n",
    "            for ann in anns:\n",
    "                cat_id = ann['category_id']\n",
    "                if cat_id in self.cat_id_to_idx:\n",
    "                    class_idx = self.cat_id_to_idx[cat_id]\n",
    "                    if class_idx < 80:\n",
    "                        target[class_idx] = 1.0\n",
    "            \n",
    "            # If no annotations, give a fixed label to avoid all-zero targets\n",
    "            if target.sum() == 0:\n",
    "                target[idx % 80] = 1.0  # Give fixed label based on index\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, target\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"COCO data loading error idx={idx}: {e}\")\n",
    "            # Return fixed dummy data\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_target = torch.zeros(80)\n",
    "            dummy_target[idx % 80] = 1.0\n",
    "            return dummy_image, dummy_target\n",
    "\n",
    "class VOCSegmentationDataset(Dataset):\n",
    "    \"\"\"VOC Segmentation Dataset - Debug version\"\"\"\n",
    "    def __init__(self, json_file, base_dir='./VOC_subset', transform=None, seg_transform=None):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                self.data = json.load(f)\n",
    "            print(f\"Successfully loaded VOC data: {len(self.data)} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading VOC JSON file {json_file}: {e}\")\n",
    "            # Create dummy data\n",
    "            self.data = [\n",
    "                {'image': f'dummy_image_{i}.jpg', 'segmentation': f'dummy_mask_{i}.png'}\n",
    "                for i in range(50)\n",
    "            ]\n",
    "        \n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.seg_transform = seg_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.data[idx]\n",
    "            \n",
    "            # Load image\n",
    "            img_path = os.path.join(self.base_dir, item['image'])\n",
    "            if not os.path.exists(img_path):\n",
    "                # Create fixed dummy image\n",
    "                image = Image.new('RGB', (224, 224), color=(64, 128, 192))\n",
    "            else:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Load segmentation mask\n",
    "            seg_path = os.path.join(self.base_dir, item['segmentation'])\n",
    "            if not os.path.exists(seg_path):\n",
    "                # Create fixed dummy mask\n",
    "                mask_array = np.zeros((224, 224), dtype=np.uint8)\n",
    "                # Create a fixed rectangular region as foreground\n",
    "                mask_array[50:150, 50:150] = 255\n",
    "                mask = Image.fromarray(mask_array, mode='L')\n",
    "            else:\n",
    "                mask = Image.open(seg_path).convert('L')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            if self.seg_transform:\n",
    "                mask = self.seg_transform(mask)\n",
    "            else:\n",
    "                mask = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor()\n",
    "                ])(mask)\n",
    "            \n",
    "            return image, mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"VOC data loading error idx={idx}: {e}\")\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_mask = torch.ones(1, 224, 224) * 0.5  # Fixed value instead of random\n",
    "            return dummy_image, dummy_mask\n",
    "\n",
    "class ImageNetDataset(Dataset):\n",
    "    \"\"\"ImageNet Classification Dataset\"\"\"\n",
    "    def __init__(self, txt_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    img_path = parts[0]\n",
    "                    try:\n",
    "                        label = int(parts[1])\n",
    "                        # Update: Change from 999 to 29 for 30 classes (0-29)\n",
    "                        label = max(0, min(label, 29))  # Changed from min(label, 999)\n",
    "                        self.samples.append((img_path, label))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                \n",
    "        print(f\"Successfully loaded ImageNet data: {len(self.samples)} samples\")\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path, label = self.samples[idx]\n",
    "            full_path = os.path.join(self.img_dir, img_path)\n",
    "            \n",
    "            if not os.path.exists(full_path):\n",
    "                # Create fixed dummy image with 30-class compatible colors\n",
    "                image = Image.new('RGB', (224, 224), color=(label % 256, (label*2) % 256, (label*3) % 256))\n",
    "            else:\n",
    "                image = Image.open(full_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet data loading error idx={idx}: {e}\")\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_label = idx % 30  # Changed from % 1000\n",
    "            return dummy_image, dummy_label\n",
    "\n",
    "class BalancedMultiTaskModel(nn.Module):\n",
    "    \"\"\"Balanced Multi-Task Model - Improved version\"\"\"\n",
    "    def __init__(self, num_classes_det=80, num_classes_cls=1000):\n",
    "        super(BalancedMultiTaskModel, self).__init__()\n",
    "        \n",
    "        print(\"Initializing multi-task model...\")\n",
    "        \n",
    "        # Use EfficientNet-B0 as shared backbone\n",
    "        try:\n",
    "            backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "            print(\"Using pre-trained EfficientNet-B0\")\n",
    "        except:\n",
    "            try:\n",
    "                backbone = models.efficientnet_b0(pretrained=True)\n",
    "                print(\"Using pre-trained EfficientNet-B0 (legacy)\")\n",
    "            except:\n",
    "                backbone = models.efficientnet_b0(pretrained=False)\n",
    "                print(\"Using non-pre-trained EfficientNet-B0\")\n",
    "            \n",
    "        self.feature_extractor = backbone.features\n",
    "        \n",
    "        # Shared feature processing layer\n",
    "        self.shared_conv = nn.Sequential(\n",
    "            nn.Conv2d(1280, 320, kernel_size=1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        # Segmentation branch\n",
    "        self.seg_branch = nn.Sequential(\n",
    "            nn.Conv2d(320, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(32, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        # Detection branch - Multi-scale features\n",
    "        self.det_global_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.det_spatial_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((3, 3)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320 * 9, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.det_classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes_det)\n",
    "        )\n",
    "        \n",
    "        # Classification branch - Enhanced version\n",
    "        self.cls_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 512),  # Increased capacity\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes_cls)\n",
    "        )\n",
    "\n",
    "        # Calculate parameter count\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Total parameters: {total_params / 1e6:.2f}M\")\n",
    "        \n",
    "        if total_params >= 8e6:\n",
    "            print(f\"Warning: Model has {total_params / 1e6:.2f}M parameters, approaching 8M limit\")\n",
    "        else:\n",
    "            print(f\"Parameter count within limit: {total_params / 1e6:.2f}M < 8M\")\n",
    "    \n",
    "    def forward(self, x, task='classification'):\n",
    "        features = self.feature_extractor(x)\n",
    "        shared_features = self.shared_conv(features)\n",
    "        \n",
    "        if task == 'segmentation':\n",
    "            return self.seg_branch(shared_features)\n",
    "        elif task == 'detection':\n",
    "            global_features = self.det_global_branch(shared_features)\n",
    "            spatial_features = self.det_spatial_branch(shared_features)\n",
    "            combined = torch.cat([global_features, spatial_features], dim=1)\n",
    "            return self.det_classifier(combined)\n",
    "        elif task == 'classification':\n",
    "            return self.cls_branch(shared_features)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "def compute_ap(pred_scores, true_labels):\n",
    "    \"\"\"Compute Average Precision for a single class\"\"\"\n",
    "    if len(pred_scores) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    sorted_indices = np.argsort(pred_scores)[::-1]\n",
    "    sorted_scores = pred_scores[sorted_indices]\n",
    "    sorted_labels = true_labels[sorted_indices]\n",
    "    \n",
    "    tp = np.cumsum(sorted_labels)\n",
    "    fp = np.cumsum(1 - sorted_labels)\n",
    "    \n",
    "    num_positives = np.sum(true_labels)\n",
    "    if num_positives == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / num_positives\n",
    "    \n",
    "    # 11-point interpolation\n",
    "    ap = 0.0\n",
    "    for t in np.arange(0, 1.1, 0.1):\n",
    "        if np.sum(recall >= t) == 0:\n",
    "            p = 0\n",
    "        else:\n",
    "            p = np.max(precision[recall >= t])\n",
    "        ap += p / 11\n",
    "    \n",
    "    return ap\n",
    "\n",
    "def compute_map(predictions, targets, num_classes=80):\n",
    "    \"\"\"Compute mAP\"\"\"\n",
    "    if predictions.shape[0] == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    aps = []\n",
    "    valid_classes = 0\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        pred_scores = predictions[:, class_idx]\n",
    "        true_labels = targets[:, class_idx]\n",
    "        \n",
    "        if np.sum(true_labels) > 0:  # Only compute for classes with positive samples\n",
    "            ap = compute_ap(pred_scores, true_labels)\n",
    "            aps.append(ap)\n",
    "            valid_classes += 1\n",
    "    \n",
    "    if valid_classes == 0:\n",
    "        print(\"Warning: No valid classes for mAP computation\")\n",
    "        return 0.0\n",
    "        \n",
    "    mean_ap = np.mean(aps)\n",
    "    print(f\"mAP computation: {valid_classes} valid classes, average AP: {mean_ap:.4f}\")\n",
    "    return mean_ap\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class EnhancedEWC:\n",
    "    \"\"\"Enhanced Elastic Weight Consolidation\"\"\"\n",
    "    def __init__(self, model, dataset_loader, task_type='classification', importance=2000):\n",
    "        self.model = model\n",
    "        # Increase importance for classification tasks\n",
    "        if task_type == 'classification':\n",
    "            self.importance = importance * 2  # Increase to 4000\n",
    "            print(f\"Classification task EWC importance set to: {self.importance}\")\n",
    "        else:\n",
    "            self.importance = importance\n",
    "            \n",
    "        self.task_type = task_type\n",
    "        self.params = {n: p.clone().detach() for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self.fisher = self._compute_fisher_information(dataset_loader)\n",
    "    \n",
    "    def _compute_fisher_information(self, dataset_loader):\n",
    "        \"\"\"Compute Fisher Information Matrix\"\"\"\n",
    "        fisher = {}\n",
    "        self.model.eval()\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        \n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                fisher[n] = torch.zeros_like(p)\n",
    "        \n",
    "        print(f\"Computing Fisher Information Matrix, task type: {self.task_type}\")\n",
    "        \n",
    "        num_batches = 0\n",
    "        max_batches = min(30, len(dataset_loader))  # Reduce batch count to save memory\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(dataset_loader):\n",
    "            if batch_idx >= max_batches:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                data = data.cuda() if torch.cuda.is_available() else data\n",
    "                target = target.cuda() if torch.cuda.is_available() else target\n",
    "                \n",
    "                # Reduce batch size\n",
    "                if data.size(0) > 2:\n",
    "                    data = data[:2]\n",
    "                    target = target[:2]\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                \n",
    "                if self.task_type == 'classification':\n",
    "                    output = self.model(data, task='classification')\n",
    "                    loss = F.cross_entropy(output, target)\n",
    "                elif self.task_type == 'detection':\n",
    "                    output = self.model(data, task='detection')\n",
    "                    loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                elif self.task_type == 'segmentation':\n",
    "                    output = self.model(data, task='segmentation')\n",
    "                    if target.dim() == 4 and target.size(1) == 1:\n",
    "                        target = target.squeeze(1)\n",
    "                    if output.dim() == 4 and output.size(1) == 1:\n",
    "                        output = output.squeeze(1)\n",
    "                    loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for n, p in self.model.named_parameters():\n",
    "                        if p.requires_grad and p.grad is not None and n in fisher:\n",
    "                            fisher[n] += p.grad.pow(2).detach()\n",
    "                \n",
    "                num_batches += 1\n",
    "                self.model.zero_grad()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Fisher computation batch {batch_idx} error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Normalize Fisher information\n",
    "        for n in fisher:\n",
    "            if num_batches > 0:\n",
    "                fisher[n] = fisher[n] / num_batches + 1e-8\n",
    "            else:\n",
    "                fisher[n] = torch.ones_like(fisher[n]) * 1e-8\n",
    "        \n",
    "        print(f\"Fisher computation completed, processed {num_batches} batches\")\n",
    "        return fisher\n",
    "    \n",
    "    def penalty(self):\n",
    "        \"\"\"Compute EWC penalty term\"\"\"\n",
    "        loss = 0\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad and n in self.fisher and n in self.params:\n",
    "                param_diff = (p - self.params[n]).pow(2)\n",
    "                fisher_weighted = self.fisher[n] * param_diff\n",
    "                loss += fisher_weighted.sum()\n",
    "        \n",
    "        return self.importance * loss\n",
    "\n",
    "class BalancedContinualLearner:\n",
    "    \"\"\"Balanced Continual Learner - Debug improved version\"\"\"\n",
    "    def __init__(self, model, learning_rate=0.0002):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, T_0=10, T_mult=2)\n",
    "        self.ewc_tasks = []\n",
    "        self.task_snapshots = []\n",
    "        self.task_best_metrics = {}\n",
    "        self.tasks_completed = 0\n",
    "        \n",
    "        self.focal_loss = FocalLoss(alpha=1, gamma=2)\n",
    "        \n",
    "        # Training history\n",
    "        self.training_history = {\n",
    "            'stage': [],\n",
    "            'mIoU': [],\n",
    "            'mAP': [],\n",
    "            'Top1_acc': []\n",
    "        }\n",
    "        \n",
    "        self.loss_history = {\n",
    "            'train_losses': [],\n",
    "            'val_losses': [],\n",
    "            'stage_names': []\n",
    "        }\n",
    "        \n",
    "        print(\"Balanced continual learner initialized\")\n",
    "    \n",
    "    def compute_iou(self, pred_mask, true_mask, threshold=0.5):\n",
    "        \"\"\"Compute IoU metric\"\"\"\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                pred_binary = (torch.sigmoid(pred_mask) > threshold).float()\n",
    "                true_binary = true_mask.float()\n",
    "                \n",
    "                intersection = (pred_binary * true_binary).sum()\n",
    "                union = pred_binary.sum() + true_binary.sum() - intersection\n",
    "                \n",
    "                if union == 0:\n",
    "                    return 1.0 if intersection == 0 else 0.0\n",
    "                return (intersection / (union + 1e-8)).item()\n",
    "        except Exception as e:\n",
    "            print(f\"IoU computation error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def save_task_snapshot(self, task_name, best_metric):\n",
    "        \"\"\"Save task snapshot\"\"\"\n",
    "        snapshot = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            snapshot[name] = param.clone().detach()\n",
    "        self.task_snapshots.append(snapshot)\n",
    "        self.task_best_metrics[task_name] = best_metric\n",
    "        print(f\"Saved task snapshot: {task_name}, metric: {best_metric:.4f}\")\n",
    "    \n",
    "    def get_adaptive_regularization_loss(self, current_task):\n",
    "        \"\"\"Adaptive regularization loss\"\"\"\n",
    "        reg_loss = 0\n",
    "        \n",
    "        # EWC regularization\n",
    "        if len(self.ewc_tasks) > 0:\n",
    "            ewc_weight = 0.001  # Reduce EWC weight\n",
    "            for ewc_task in self.ewc_tasks:\n",
    "                reg_loss += ewc_weight * ewc_task.penalty()\n",
    "        \n",
    "        # L2 regularization\n",
    "        if len(self.task_snapshots) > 0:\n",
    "            l2_loss = 0\n",
    "            for snapshot in self.task_snapshots:\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if name in snapshot:\n",
    "                        l2_loss += torch.norm(param - snapshot[name]) ** 2\n",
    "            reg_loss += 0.0001 * l2_loss  # Reduce L2 weight\n",
    "        \n",
    "        return reg_loss\n",
    "    \n",
    "    def dedicated_classification_fine_tuning(self, data_loaders, target_top1, max_epochs=10):\n",
    "        \"\"\"Dedicated classification fine-tuning\"\"\"\n",
    "        print(f\"\\nStarting dedicated classification fine-tuning\")\n",
    "        print(f\"Target Top-1 accuracy: {target_top1:.2f}%\")\n",
    "        \n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        \n",
    "        # Save original learning rate\n",
    "        original_lr = self.optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Use higher learning rate for classification fine-tuning\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0005  # Higher learning rate\n",
    "        \n",
    "        best_top1 = 0\n",
    "        best_model_state = None\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(f\"\\n--- Classification Fine-tuning Epoch {epoch+1}/{max_epochs} ---\")\n",
    "            \n",
    "            # Training\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(imagenet_train_loader):\n",
    "                if batch_idx >= 15:  # Limit batch count\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(data, task='classification')\n",
    "                    \n",
    "                    # Classification loss\n",
    "                    cls_loss = F.cross_entropy(output, target, label_smoothing=0.1)\n",
    "                    \n",
    "                    # Reduce regularization strength\n",
    "                    total_loss = cls_loss\n",
    "                    if len(self.ewc_tasks) > 0:\n",
    "                        reg_loss = 0.00001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                        total_loss += reg_loss\n",
    "                    \n",
    "                    total_loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += total_loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        acc = (predicted == target).float().mean().item()\n",
    "                        epoch_acc += acc\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Classification training batch error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Validation\n",
    "            if batch_count > 0:\n",
    "                avg_loss = epoch_loss / batch_count\n",
    "                avg_acc = epoch_acc / batch_count\n",
    "                \n",
    "                try:\n",
    "                    val_top1, _ = self.evaluate(imagenet_val_loader, 'classification')\n",
    "                    print(f\"Epoch {epoch+1}: Train loss={avg_loss:.4f}, Train acc={avg_acc:.4f}, Val Top-1={val_top1:.2f}%\")\n",
    "                    \n",
    "                    if val_top1 > best_top1:\n",
    "                        best_top1 = val_top1\n",
    "                        best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                        patience_counter = 0\n",
    "                        print(f\"New best classification accuracy: {best_top1:.2f}%\")\n",
    "                        \n",
    "                        if val_top1 >= target_top1:\n",
    "                            print(f\"Target accuracy reached! Stopping fine-tuning.\")\n",
    "                            break\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= patience:\n",
    "                            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Validation error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(f\"Restored best classification model Top-1: {best_top1:.2f}%\")\n",
    "        \n",
    "        # Restore original learning rate\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = original_lr\n",
    "        \n",
    "        return best_top1\n",
    "    \n",
    "    def balanced_multi_task_fine_tuning(self, data_loaders, target_metrics, max_epochs=15):\n",
    "        \"\"\"Balanced multi-task fine-tuning - Improved version\"\"\"\n",
    "        print(f\"\\n === Balanced Multi-Task Fine-Tuning ===\")\n",
    "        \n",
    "        # Remove extra safety margins, use original targets\n",
    "        enhanced_target_metrics = {\n",
    "            'mIoU': target_metrics.get('mIoU', 0),\n",
    "            'mAP': target_metrics.get('mAP', 0),\n",
    "            'Top1_acc': target_metrics.get('Top1_acc', 0)  # No extra margin\n",
    "        }\n",
    "        \n",
    "        print(f\"Target metrics:\")\n",
    "        print(f\"mIoU: ≥ {enhanced_target_metrics['mIoU']:.2f}%\")\n",
    "        print(f\"mAP: ≥ {enhanced_target_metrics['mAP']:.2f}%\")\n",
    "        print(f\"Top-1: ≥ {enhanced_target_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Get current performance\n",
    "        current_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "        print(f\"Current metrics: mIoU={current_metrics['mIoU']:.2f}%, \"\n",
    "            f\"mAP={current_metrics['mAP']:.2f}%, Top1={current_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Check which tasks need improvement\n",
    "        need_improvement = {\n",
    "            'segmentation': current_metrics['mIoU'] < enhanced_target_metrics['mIoU'],\n",
    "            'detection': current_metrics['mAP'] < enhanced_target_metrics['mAP'],\n",
    "            'classification': current_metrics['Top1_acc'] < enhanced_target_metrics['Top1_acc']\n",
    "        }\n",
    "        \n",
    "        tasks_to_improve = [task for task, need in need_improvement.items() if need]\n",
    "        \n",
    "        if not tasks_to_improve:\n",
    "            print(\"All tasks have reached target metrics!\")\n",
    "            return current_metrics\n",
    "        \n",
    "        print(f\"Tasks needing improvement: {tasks_to_improve}\")\n",
    "        \n",
    "        # If only classification task needs improvement, use dedicated classification fine-tuning\n",
    "        if tasks_to_improve == ['classification']:\n",
    "            print(\"Only classification task needs improvement, using dedicated classification fine-tuning\")\n",
    "            final_top1 = self.dedicated_classification_fine_tuning(\n",
    "                data_loaders, enhanced_target_metrics['Top1_acc'], max_epochs=15\n",
    "            )\n",
    "            \n",
    "            # Re-evaluate all tasks\n",
    "            final_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "            return final_metrics\n",
    "        \n",
    "        # Set fine-tuning learning rate\n",
    "        original_lr = self.optimizer.param_groups[0]['lr']\n",
    "        finetune_lr = original_lr * 0.5  # Conservative learning rate\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = finetune_lr\n",
    "        \n",
    "        print(f\"Set fine-tuning learning rate: {finetune_lr:.8f}\")\n",
    "        \n",
    "        # Prepare data loaders\n",
    "        voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "        coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        \n",
    "        best_combined_score = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(f\"\\n--- Multi-task Fine-tuning Epoch {epoch+1}/{max_epochs} ---\")\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_losses = {'seg': [], 'det': [], 'cls': []}\n",
    "            epoch_metrics = {'seg': [], 'det': [], 'cls': []}\n",
    "            \n",
    "            # Create data iterators\n",
    "            try:\n",
    "                seg_iter = iter(voc_train_loader) if 'segmentation' in tasks_to_improve else None\n",
    "                det_iter = iter(coco_train_loader) if 'detection' in tasks_to_improve else None\n",
    "                cls_iter = iter(imagenet_train_loader) if 'classification' in tasks_to_improve else None\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating iterators: {e}\")\n",
    "                break\n",
    "            \n",
    "            # Calculate training batches\n",
    "            available_lengths = []\n",
    "            if seg_iter: available_lengths.append(len(voc_train_loader))\n",
    "            if det_iter: available_lengths.append(len(coco_train_loader))\n",
    "            if cls_iter: available_lengths.append(len(imagenet_train_loader))\n",
    "            \n",
    "            if not available_lengths:\n",
    "                print(\"No tasks need improvement\")\n",
    "                break\n",
    "                \n",
    "            train_batches_per_task = min(min(available_lengths), 15)  # Limit batch count\n",
    "            \n",
    "            # Alternating training for all tasks needing improvement\n",
    "            for batch_idx in range(train_batches_per_task):\n",
    "                \n",
    "                # 1. Segmentation training\n",
    "                if 'segmentation' in tasks_to_improve and seg_iter:\n",
    "                    try:\n",
    "                        data, target = next(seg_iter)\n",
    "                        if torch.cuda.is_available():\n",
    "                            data, target = data.cuda(), target.cuda()\n",
    "                        \n",
    "                        self.optimizer.zero_grad()\n",
    "                        output = self.model(data, task='segmentation')\n",
    "                        \n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        seg_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1e-6) / (union + 1e-6)\n",
    "                        \n",
    "                        seg_total_loss = seg_loss + dice_loss\n",
    "                        \n",
    "                        # Less regularization\n",
    "                        if len(self.ewc_tasks) > 0:\n",
    "                            reg_loss = 0.0001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                            seg_total_loss += reg_loss\n",
    "                        \n",
    "                        seg_total_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                        self.optimizer.step()\n",
    "                        \n",
    "                        epoch_losses['seg'].append(seg_total_loss.item())\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            iou = self.compute_iou(output, target)\n",
    "                            epoch_metrics['seg'].append(iou)\n",
    "                        \n",
    "                    except (StopIteration, Exception) as e:\n",
    "                        continue\n",
    "                \n",
    "                # 2. Detection training\n",
    "                if 'detection' in tasks_to_improve and det_iter:\n",
    "                    try:\n",
    "                        data, target = next(det_iter)\n",
    "                        if torch.cuda.is_available():\n",
    "                            data, target = data.cuda(), target.cuda()\n",
    "                        \n",
    "                        self.optimizer.zero_grad()\n",
    "                        output = self.model(data, task='detection')\n",
    "                        \n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        det_total_loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        # Less regularization\n",
    "                        if len(self.ewc_tasks) > 0:\n",
    "                            reg_loss = 0.0001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                            det_total_loss += reg_loss\n",
    "                        \n",
    "                        det_total_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                        self.optimizer.step()\n",
    "                        \n",
    "                        epoch_losses['det'].append(det_total_loss.item())\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            pred_binary = torch.sigmoid(output) > 0.5\n",
    "                            acc = (pred_binary == target.bool()).float().mean().item()\n",
    "                            epoch_metrics['det'].append(acc)\n",
    "                        \n",
    "                    except (StopIteration, Exception) as e:\n",
    "                        continue\n",
    "                \n",
    "                # 3. Classification training - Special handling\n",
    "                if 'classification' in tasks_to_improve and cls_iter:\n",
    "                    # Train classification task twice to enhance learning\n",
    "                    for _ in range(2):\n",
    "                        try:\n",
    "                            data, target = next(cls_iter)\n",
    "                            if torch.cuda.is_available():\n",
    "                                data, target = data.cuda(), target.cuda()\n",
    "                            \n",
    "                            self.optimizer.zero_grad()\n",
    "                            output = self.model(data, task='classification')\n",
    "                            \n",
    "                            cls_loss = F.cross_entropy(output, target, label_smoothing=0.1)\n",
    "                            \n",
    "                            # Minimal regularization\n",
    "                            if len(self.ewc_tasks) > 0:\n",
    "                                reg_loss = 0.00001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                                cls_loss += reg_loss\n",
    "                            \n",
    "                            cls_loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                            self.optimizer.step()\n",
    "                            \n",
    "                            epoch_losses['cls'].append(cls_loss.item())\n",
    "                            \n",
    "                            with torch.no_grad():\n",
    "                                _, predicted = torch.max(output, 1)\n",
    "                                acc = (predicted == target).float().mean().item()\n",
    "                                epoch_metrics['cls'].append(acc)\n",
    "                            \n",
    "                        except (StopIteration, Exception) as e:\n",
    "                            break\n",
    "            \n",
    "            # Calculate epoch average metrics\n",
    "            avg_seg_metric = np.mean(epoch_metrics['seg']) if epoch_metrics['seg'] else 0\n",
    "            avg_det_metric = np.mean(epoch_metrics['det']) if epoch_metrics['det'] else 0\n",
    "            avg_cls_metric = np.mean(epoch_metrics['cls']) if epoch_metrics['cls'] else 0\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} training metrics:\")\n",
    "            if epoch_metrics['seg']:\n",
    "                print(f\"  Segmentation IoU: {avg_seg_metric:.4f}\")\n",
    "            if epoch_metrics['det']:\n",
    "                print(f\"  Detection accuracy: {avg_det_metric:.4f}\")\n",
    "            if epoch_metrics['cls']:\n",
    "                print(f\"  Classification accuracy: {avg_cls_metric:.4f}\")\n",
    "            \n",
    "            # Validate all tasks\n",
    "            try:\n",
    "                val_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "                print(f\"Epoch {epoch+1} validation metrics:\")\n",
    "                print(f\"  mIoU: {val_metrics['mIoU']:.2f}%\")\n",
    "                print(f\"  mAP: {val_metrics['mAP']:.2f}%\")\n",
    "                print(f\"  Top-1: {val_metrics['Top1_acc']:.2f}%\")\n",
    "                \n",
    "                # Calculate combined score\n",
    "                combined_score = (val_metrics['mIoU'] + val_metrics['mAP'] + val_metrics['Top1_acc']) / 3\n",
    "                \n",
    "                if combined_score > best_combined_score:\n",
    "                    best_combined_score = combined_score\n",
    "                    best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    print(f\"New best combined score: {combined_score:.2f}\")\n",
    "                    \n",
    "                    # Check if all tasks meet targets\n",
    "                    all_targets_met = (\n",
    "                        val_metrics['mIoU'] >= enhanced_target_metrics['mIoU'] and\n",
    "                        val_metrics['mAP'] >= enhanced_target_metrics['mAP'] and\n",
    "                        val_metrics['Top1_acc'] >= enhanced_target_metrics['Top1_acc']\n",
    "                    )\n",
    "                    \n",
    "                    if all_targets_met:\n",
    "                        print(f\"All target metrics achieved! Stopping fine-tuning.\")\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Validation error epoch {epoch+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(\"Restored best fine-tuned model\")\n",
    "        \n",
    "        # Restore original learning rate\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = original_lr\n",
    "        \n",
    "        # Final evaluation\n",
    "        try:\n",
    "            final_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "            print(f\"\\nFinal fine-tuning results:\")\n",
    "            print(f\"mIoU: {final_metrics['mIoU']:.2f}% (target: ≥{target_metrics.get('mIoU', 0):.2f}%)\")\n",
    "            print(f\"mAP: {final_metrics['mAP']:.2f}% (target: ≥{target_metrics.get('mAP', 0):.2f}%)\")\n",
    "            print(f\"Top-1: {final_metrics['Top1_acc']:.2f}% (target: ≥{enhanced_target_metrics['Top1_acc']:.2f}%)\")\n",
    "            \n",
    "            return final_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Final evaluation error: {e}\")\n",
    "            return current_metrics\n",
    "    \n",
    "    def train_stage(self, train_loader, val_loader, task_type, num_epochs=30, stage_name=\"\"):\n",
    "        \"\"\"Training stage - Improved version\"\"\"\n",
    "        print(f\"\\n=== Training Stage: {stage_name} ===\")\n",
    "        print(f\"Task type: {task_type}\")\n",
    "        \n",
    "        # Adjust parameters based on task type\n",
    "        if task_type == 'detection':\n",
    "            num_epochs = 25  # Reduce epoch count\n",
    "            patience = 15\n",
    "        elif task_type == 'segmentation':\n",
    "            num_epochs = 20\n",
    "            patience = 12\n",
    "        else:  # classification\n",
    "            num_epochs = 20\n",
    "            patience = 10\n",
    "        \n",
    "        print(f\"Set {num_epochs} epochs, early stopping patience: {patience}\")\n",
    "        \n",
    "        best_metric = 0\n",
    "        best_model_state = None\n",
    "        stage_train_losses = []\n",
    "        stage_val_losses = []\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Learning rate adjustment\n",
    "        if self.tasks_completed > 0:\n",
    "            reduction_factor = 0.95 ** self.tasks_completed  # Gentler decay\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] *= reduction_factor\n",
    "            print(f\"Adjusted learning rate to: {self.optimizer.param_groups[0]['lr']:.8f}\")\n",
    "        \n",
    "        # Ensure all parameters are trainable\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            train_metrics = []\n",
    "            batch_count = 0\n",
    "            \n",
    "            # Limit batches per epoch to save time\n",
    "            max_batches_per_epoch = min(len(train_loader), 50)\n",
    "            \n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", total=max_batches_per_epoch)\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "                if batch_idx >= max_batches_per_epoch:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(data, task=task_type)\n",
    "                    \n",
    "                    # Calculate task-specific loss\n",
    "                    if task_type == 'classification':\n",
    "                        task_loss = F.cross_entropy(output, target)\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        acc = (predicted == target).float().mean().item()\n",
    "                        train_metrics.append(acc)\n",
    "                        \n",
    "                    elif task_type == 'detection':\n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        task_loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        pred_binary = torch.sigmoid(output) > 0.5\n",
    "                        acc = (pred_binary == target.bool()).float().mean().item()\n",
    "                        train_metrics.append(acc)\n",
    "                        \n",
    "                    elif task_type == 'segmentation':\n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1e-6) / (union + 1e-6)\n",
    "                        \n",
    "                        task_loss = bce_loss + dice_loss\n",
    "                        \n",
    "                        iou = self.compute_iou(output, target)\n",
    "                        train_metrics.append(iou)\n",
    "                    \n",
    "                    # Add regularization\n",
    "                    total_loss_val = task_loss\n",
    "                    if len(self.ewc_tasks) > 0 or len(self.task_snapshots) > 0:\n",
    "                        reg_loss = self.get_adaptive_regularization_loss(task_type)\n",
    "                        total_loss_val += reg_loss\n",
    "                    \n",
    "                    total_loss_val.backward()\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    total_loss += total_loss_val.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    avg_loss = total_loss / batch_count\n",
    "                    avg_metric = np.mean(train_metrics) if train_metrics else 0\n",
    "                    progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}', 'Metric': f'{avg_metric:.4f}'})\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Training batch {batch_idx} error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            progress_bar.close()\n",
    "            \n",
    "            # Validation\n",
    "            try:\n",
    "                val_metric, val_loss = self.evaluate(val_loader, task_type)\n",
    "            except Exception as e:\n",
    "                print(f\"Validation stage error: {e}\")\n",
    "                val_metric, val_loss = 0.0, 1.0\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            if epoch % 5 == 0 and epoch > 0:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Record and check early stopping\n",
    "            if batch_count > 0:\n",
    "                avg_train_loss = total_loss / batch_count\n",
    "                stage_train_losses.append(avg_train_loss)\n",
    "                stage_val_losses.append(val_loss)\n",
    "                \n",
    "                avg_train_metric = np.mean(train_metrics) if train_metrics else 0\n",
    "                print(f\"Epoch {epoch+1}: Loss={avg_train_loss:.4f}, \"\n",
    "                      f\"Train metric={avg_train_metric:.4f}, Val metric={val_metric:.4f}\")\n",
    "                \n",
    "                if val_metric > best_metric:\n",
    "                    best_metric = val_metric\n",
    "                    best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                    print(f\"New best {task_type} metric: {best_metric:.4f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(\"Restored best model state\")\n",
    "        \n",
    "        # Save snapshot\n",
    "        self.save_task_snapshot(stage_name, best_metric)\n",
    "        \n",
    "        # Record history\n",
    "        self.loss_history['train_losses'].append(stage_train_losses)\n",
    "        self.loss_history['val_losses'].append(stage_val_losses)\n",
    "        self.loss_history['stage_names'].append(stage_name)\n",
    "        \n",
    "        # Record metrics\n",
    "        self.training_history['stage'].append(stage_name)\n",
    "        if task_type == 'segmentation':\n",
    "            self.training_history['mIoU'].append(best_metric * 100)\n",
    "            self.training_history['mAP'].append(0)\n",
    "            self.training_history['Top1_acc'].append(0)\n",
    "        elif task_type == 'detection':\n",
    "            self.training_history['mIoU'].append(0)\n",
    "            self.training_history['mAP'].append(best_metric * 100)\n",
    "            self.training_history['Top1_acc'].append(0)\n",
    "        elif task_type == 'classification':\n",
    "            self.training_history['mIoU'].append(0)\n",
    "            self.training_history['mAP'].append(0)\n",
    "            self.training_history['Top1_acc'].append(best_metric)\n",
    "        \n",
    "        # Initialize EWC\n",
    "        try:\n",
    "            print(\"Computing Fisher information for EWC...\")\n",
    "            importance = 800\n",
    "            ewc = EnhancedEWC(self.model, train_loader, task_type=task_type, importance=importance)\n",
    "            self.ewc_tasks.append(ewc)\n",
    "            print(f\"EWC initialized successfully, task {self.tasks_completed + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"EWC initialization failed: {e}\")\n",
    "        \n",
    "        self.tasks_completed += 1\n",
    "        return best_metric\n",
    "    \n",
    "    def evaluate(self, val_loader, task_type):\n",
    "        \"\"\"Evaluate model performance - Improved version\"\"\"\n",
    "        self.model.eval()\n",
    "        total_metric = 0\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        # Data collection for mAP computation\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        max_eval_batches = min(len(val_loader), 30)  # Limit evaluation batch count\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                if batch_idx >= max_eval_batches:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    output = self.model(data, task=task_type)\n",
    "                    \n",
    "                    if task_type == 'classification':\n",
    "                        loss = F.cross_entropy(output, target)\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        correct = (predicted == target).sum().item()\n",
    "                        total_metric += correct\n",
    "                        num_samples += target.size(0)\n",
    "                        \n",
    "                    elif task_type == 'segmentation':\n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1) / (union + 1)\n",
    "                        loss = bce_loss + dice_loss\n",
    "                        \n",
    "                        for i in range(output.size(0)):\n",
    "                            iou = self.compute_iou(output[i:i+1], target[i:i+1])\n",
    "                            total_metric += iou\n",
    "                            num_samples += 1\n",
    "                            \n",
    "                    elif task_type == 'detection':\n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        # Collect predictions and true labels for mAP computation\n",
    "                        pred_probs = torch.sigmoid(output).cpu().numpy()\n",
    "                        target_np = target.cpu().numpy()\n",
    "                        \n",
    "                        all_predictions.extend(pred_probs)\n",
    "                        all_targets.extend(target_np)\n",
    "                        \n",
    "                        num_samples += output.size(0)\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Evaluation batch {batch_idx} error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if num_samples == 0:\n",
    "            print(\"Number of evaluation samples is 0\")\n",
    "            return 0.0, 1.0\n",
    "        \n",
    "        avg_loss = total_loss / max_eval_batches if max_eval_batches > 0 else 1.0\n",
    "        \n",
    "        if task_type == 'classification':\n",
    "            accuracy = 100.0 * total_metric / num_samples\n",
    "            print(f\"Classification evaluation: {total_metric}/{num_samples} correct, accuracy: {accuracy:.2f}%\")\n",
    "            return accuracy, avg_loss\n",
    "        elif task_type == 'detection':\n",
    "            if all_predictions and all_targets:\n",
    "                all_predictions = np.array(all_predictions)\n",
    "                all_targets = np.array(all_targets)\n",
    "                map_score = compute_map(all_predictions, all_targets, num_classes=80)\n",
    "                print(f\"Detection evaluation: mAP = {map_score:.4f}\")\n",
    "                return map_score, avg_loss\n",
    "            else:\n",
    "                print(\"Insufficient detection evaluation data\")\n",
    "                return 0.0, avg_loss\n",
    "        else:  # segmentation\n",
    "            avg_iou = total_metric / num_samples\n",
    "            print(f\"Segmentation evaluation: Average IoU = {avg_iou:.4f}\")\n",
    "            return avg_iou, avg_loss\n",
    "    \n",
    "    def evaluate_all_tasks(self, data_loaders):\n",
    "        \"\"\"Evaluate all tasks\"\"\"\n",
    "        print(\"\\n=== Evaluating All Tasks ===\")\n",
    "        \n",
    "        # VOC Segmentation\n",
    "        try:\n",
    "            voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "            voc_metric, _ = self.evaluate(voc_val_loader, 'segmentation')\n",
    "            print(f\"VOC segmentation mIoU: {voc_metric * 100:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"VOC evaluation error: {e}\")\n",
    "            voc_metric = 0\n",
    "        \n",
    "        # COCO Detection\n",
    "        try:\n",
    "            coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "            coco_metric, _ = self.evaluate(coco_val_loader, 'detection')\n",
    "            print(f\"COCO detection mAP: {coco_metric * 100:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"COCO evaluation error: {e}\")\n",
    "            coco_metric = 0\n",
    "        \n",
    "        # ImageNet Classification\n",
    "        try:\n",
    "            imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "            imagenet_metric, _ = self.evaluate(imagenet_val_loader, 'classification')\n",
    "            print(f\"ImageNet classification Top-1: {imagenet_metric:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet evaluation error: {e}\")\n",
    "            imagenet_metric = 0\n",
    "        \n",
    "        return {\n",
    "            'mIoU': voc_metric * 100,\n",
    "            'mAP': coco_metric * 100,\n",
    "            'Top1_acc': imagenet_metric\n",
    "        }\n",
    "    \n",
    "    def check_forgetting_criterion(self, final_metrics, base_metrics):\n",
    "        \"\"\"Check forgetting criterion\"\"\"\n",
    "        current_miou = final_metrics.get('mIoU', 0)\n",
    "        current_map = final_metrics.get('mAP', 0)\n",
    "        current_top1 = final_metrics.get('Top1_acc', 0)\n",
    "        \n",
    "        miou_ok = current_miou >= (base_metrics.get('mIoU', 0) - 5)\n",
    "        map_ok = current_map >= (base_metrics.get('mAP', 0) - 5)\n",
    "        top1_ok = current_top1 >= (base_metrics.get('Top1_acc', 0) - 5)\n",
    "        \n",
    "        print(f\"\\nForgetting criterion check:\")\n",
    "        print(f\"mIoU: {current_miou:.2f}% (≥ {base_metrics.get('mIoU', 0) - 5:.2f}%) - {'Passed' if miou_ok else 'Failed'}\")\n",
    "        print(f\"mAP: {current_map:.2f}% (≥ {base_metrics.get('mAP', 0) - 5:.2f}%) - {'Passed' if map_ok else 'Failed'}\")\n",
    "        print(f\"Top-1: {current_top1:.2f}% (≥ {base_metrics.get('Top1_acc', 0) - 5:.2f}%) - {'Passed' if top1_ok else 'Failed'}\")\n",
    "        \n",
    "        return miou_ok and map_ok and top1_ok\n",
    "    \n",
    "    def plot_loss_curves(self, save_path='balanced_training_losses.png'):\n",
    "        \"\"\"Plot loss curves\"\"\"\n",
    "        if not self.loss_history['stage_names']:\n",
    "            print(\"No loss history to plot\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            num_stages = len(self.loss_history['stage_names'])\n",
    "            fig, axes = plt.subplots(1, num_stages, figsize=(5*num_stages, 4))\n",
    "            if num_stages == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, stage_name in enumerate(self.loss_history['stage_names']):\n",
    "                if i < len(self.loss_history['train_losses']):\n",
    "                    train_losses = self.loss_history['train_losses'][i]\n",
    "                    val_losses = self.loss_history['val_losses'][i]\n",
    "                    epochs = range(1, len(train_losses) + 1)\n",
    "                    \n",
    "                    axes[i].plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "                    axes[i].plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "                    axes[i].set_xlabel('Epoch')\n",
    "                    axes[i].set_ylabel('Loss')\n",
    "                    axes[i].set_title(f'{stage_name}')\n",
    "                    axes[i].legend()\n",
    "                    axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"Loss curves saved to: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting loss curves: {e}\")\n",
    "\n",
    "def get_improved_transforms():\n",
    "    \"\"\"Get improved data transforms - Fixed randomness\"\"\"\n",
    "    # Use fixed random seed to ensure consistency in data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(0.3),  # Reduce randomness\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.02),  # Reduce variation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    seg_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform, seg_transform\n",
    "\n",
    "def create_data_loaders():\n",
    "    \"\"\"Create data loaders\"\"\"\n",
    "    \n",
    "    train_transform, val_transform, seg_transform = get_improved_transforms()\n",
    "    \n",
    "    print(\"Checking dataset paths...\")\n",
    "    \n",
    "    # VOC segmentation dataset\n",
    "    voc_json_path = './VOC_subset/train_list.json'\n",
    "    voc_base_dir = './VOC_subset'\n",
    "    if os.path.exists(voc_json_path):\n",
    "        print(f\"Found VOC JSON: {voc_json_path}\")\n",
    "        voc_train_dataset = VOCSegmentationDataset(\n",
    "            json_file=voc_json_path,\n",
    "            base_dir=voc_base_dir,\n",
    "            transform=train_transform,\n",
    "            seg_transform=seg_transform\n",
    "        )\n",
    "        voc_val_dataset = VOCSegmentationDataset(\n",
    "            json_file=voc_json_path,\n",
    "            base_dir=voc_base_dir,\n",
    "            transform=val_transform,\n",
    "            seg_transform=seg_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"VOC JSON not found: {voc_json_path}\")\n",
    "        print(\"Creating dummy VOC dataset...\")\n",
    "        # Create fixed dummy data\n",
    "        voc_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), torch.ones(50, 1, 224, 224) * 0.5\n",
    "        )\n",
    "        voc_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), torch.ones(20, 1, 224, 224) * 0.5\n",
    "        )\n",
    "    \n",
    "    # COCO detection dataset\n",
    "    coco_train_json = './coco_subset/COCO_train.json'\n",
    "    coco_val_json = './coco_subset/COCO_val.json'\n",
    "    coco_train_dir = './coco_subset/train'\n",
    "    coco_val_dir = './coco_subset/val'\n",
    "    \n",
    "    if os.path.exists(coco_train_json) and os.path.exists(coco_train_dir):\n",
    "        print(f\"Found COCO training set: {coco_train_json} and {coco_train_dir}\")\n",
    "        coco_train_dataset = COCODataset(\n",
    "            json_file=coco_train_json,\n",
    "            img_dir=coco_train_dir,\n",
    "            transform=train_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"COCO training set not found: {coco_train_json} or {coco_train_dir}\")\n",
    "        print(\"Creating dummy COCO training dataset...\")\n",
    "        # Create fixed dummy data\n",
    "        fake_targets = torch.zeros(50, 80)\n",
    "        for i in range(50):\n",
    "            fake_targets[i, i % 80] = 1.0  # Each sample has one fixed label\n",
    "        coco_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), fake_targets\n",
    "        )\n",
    "    \n",
    "    if os.path.exists(coco_val_json) and os.path.exists(coco_val_dir):\n",
    "        print(f\"Found COCO validation set: {coco_val_json} and {coco_val_dir}\")\n",
    "        coco_val_dataset = COCODataset(\n",
    "            json_file=coco_val_json,\n",
    "            img_dir=coco_val_dir,\n",
    "            transform=val_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"COCO validation set not found: {coco_val_json} or {coco_val_dir}\")\n",
    "        print(\"Creating dummy COCO validation dataset...\")\n",
    "        fake_targets = torch.zeros(20, 80)\n",
    "        for i in range(20):\n",
    "            fake_targets[i, i % 80] = 1.0\n",
    "        coco_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), fake_targets\n",
    "        )\n",
    "    \n",
    "    # ImageNet classification dataset\n",
    "    imagenet_train_txt = './imagenetv2_subset/imagenetv2_train.txt'\n",
    "    imagenet_val_txt = './imagenetv2_subset/imagenetv2_val.txt'\n",
    "    imagenet_img_dir = './imagenetv2_subset/imagenetv2'\n",
    "    \n",
    "    if os.path.exists(imagenet_train_txt) and os.path.exists(imagenet_img_dir):\n",
    "        print(f\"Found ImageNet training set: {imagenet_train_txt} and {imagenet_img_dir}\")\n",
    "        imagenet_train_dataset = ImageNetDataset(\n",
    "            txt_file=imagenet_train_txt,\n",
    "            img_dir=imagenet_img_dir,\n",
    "            transform=train_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"ImageNet training set not found: {imagenet_train_txt} or {imagenet_img_dir}\")\n",
    "        print(\"Creating dummy ImageNet training dataset...\")\n",
    "        # Create fixed dummy data with 30 classes\n",
    "        fake_labels = torch.tensor([i % 30 for i in range(50)])\n",
    "        imagenet_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), fake_labels\n",
    "        )\n",
    "        \n",
    "    if os.path.exists(imagenet_val_txt) and os.path.exists(imagenet_img_dir):\n",
    "        print(f\"Found ImageNet validation set: {imagenet_val_txt} and {imagenet_img_dir}\")\n",
    "        imagenet_val_dataset = ImageNetDataset(\n",
    "            txt_file=imagenet_val_txt,\n",
    "            img_dir=imagenet_img_dir,\n",
    "            transform=val_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"ImageNet validation set not found: {imagenet_val_txt} or {imagenet_img_dir}\")\n",
    "        print(\"Creating dummy ImageNet validation dataset...\")\n",
    "        fake_labels = torch.tensor([i % 30 for i in range(20)])\n",
    "        imagenet_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), fake_labels\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Create data loaders\n",
    "    batch_size = 8  # Reduce batch size to save memory\n",
    "    \n",
    "    # Set fixed random seed to ensure DataLoader consistency\n",
    "    def worker_init_fn(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    try:\n",
    "        voc_train_loader = DataLoader(\n",
    "            voc_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        voc_val_loader = DataLoader(\n",
    "            voc_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        coco_train_loader = DataLoader(\n",
    "            coco_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        coco_val_loader = DataLoader(\n",
    "            coco_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        imagenet_train_loader = DataLoader(\n",
    "            imagenet_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        imagenet_val_loader = DataLoader(\n",
    "            imagenet_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        print(\"All data loaders created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating data loaders: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'voc': (voc_train_loader, voc_val_loader),\n",
    "        'coco': (coco_train_loader, coco_val_loader),\n",
    "        'imagenet': (imagenet_train_loader, imagenet_val_loader)\n",
    "    }\n",
    "\n",
    "def test_balanced_model():\n",
    "    \"\"\"Test balanced model architecture\"\"\"\n",
    "    print(\"Testing balanced model architecture...\")\n",
    "    \n",
    "    try:\n",
    "        model = BalancedMultiTaskModel(num_classes_det=80, num_classes_cls=1000)\n",
    "        model.eval()\n",
    "        \n",
    "        batch_size = 4\n",
    "        fake_images = torch.randn(batch_size, 3, 224, 224)\n",
    "        \n",
    "        print(f\"Input shape: {fake_images.shape}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            det_output = model(fake_images, task='detection')\n",
    "            seg_output = model(fake_images, task='segmentation')\n",
    "            cls_output = model(fake_images, task='classification')\n",
    "            \n",
    "            print(f\"Detection output shape: {det_output.shape}\")\n",
    "            print(f\"Segmentation output shape: {seg_output.shape}\")\n",
    "            print(f\"Classification output shape: {cls_output.shape}\")\n",
    "        \n",
    "        print(\"Balanced model architecture test completed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Model test failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def test_single_batch(data_loaders):\n",
    "    \"\"\"Test single batch loading\"\"\"\n",
    "    print(\"Testing single batch loading...\")\n",
    "    \n",
    "    if data_loaders is None:\n",
    "        print(\"Data loaders unavailable\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test VOC loader\n",
    "        print(\"Testing VOC loader...\")\n",
    "        voc_train_loader, _ = data_loaders['voc']\n",
    "        try:\n",
    "            batch = next(iter(voc_train_loader))\n",
    "            print(f\"VOC batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"VOC batch failed: {e}\")\n",
    "        \n",
    "        # Test COCO loader\n",
    "        print(\"Testing COCO loader...\")\n",
    "        coco_train_loader, _ = data_loaders['coco']\n",
    "        try:\n",
    "            batch = next(iter(coco_train_loader))\n",
    "            print(f\"COCO batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "            print(f\"COCO target range: [{batch[1].min():.2f}, {batch[1].max():.2f}]\")\n",
    "            print(f\"COCO target type: {batch[1].dtype}\")\n",
    "        except Exception as e:\n",
    "            print(f\"COCO batch failed: {e}\")\n",
    "        \n",
    "        # Test ImageNet loader\n",
    "        print(\"Testing ImageNet loader...\")\n",
    "        imagenet_train_loader, _ = data_loaders['imagenet']\n",
    "        try:\n",
    "            batch = next(iter(imagenet_train_loader))\n",
    "            print(f\"ImageNet batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet batch failed: {e}\")\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"test_single_batch error: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    \n",
    "    # First set random seed\n",
    "    set_random_seed(42)\n",
    "    # Check CUDA availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    else:\n",
    "        print(\"CUDA unavailable, using CPU\")\n",
    "    \n",
    "    # Test model architecture\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Testing Model Architecture\")\n",
    "    print(\"=\"*50)\n",
    "    if not test_balanced_model():\n",
    "        print(\"Model test failed, exiting...\")\n",
    "        return None\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Creating Data Loaders\")\n",
    "    print(\"=\"*50)\n",
    "    data_loaders = create_data_loaders()\n",
    "    if data_loaders is None:\n",
    "        print(\"Failed to create data loaders, exiting...\")\n",
    "        return None\n",
    "    \n",
    "    # Test data loading\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Testing Data Loading\")\n",
    "    print(\"=\"*50)\n",
    "    if not test_single_batch(data_loaders):\n",
    "        print(\"Data loading test failed, but continuing execution...\")\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Initializing Model\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        model = BalancedMultiTaskModel(num_classes_det=80, num_classes_cls=1000)\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "        else:\n",
    "            print(\"Model using CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model initialization failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Initialize learner\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Initializing Learner\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        learner = BalancedContinualLearner(model, learning_rate=0.0002)\n",
    "        print(\"Balanced continual learner initialization completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Learner initialization failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Stage 1: VOC Segmentation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 1: VOC Segmentation Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "        miou_base = learner.train_stage(voc_train_loader, voc_val_loader, \n",
    "                                        'segmentation', num_epochs=20, stage_name=\"VOC segmentation\")\n",
    "        print(f\"VOC segmentation baseline mIoU: {miou_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 1\n",
    "    print(\"\\n--- Evaluation after Stage 1 ---\")\n",
    "    try:\n",
    "        stage1_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 evaluation error: {e}\")\n",
    "        stage1_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Stage 2: COCO Detection\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 2: COCO Detection Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "        map_base = learner.train_stage(coco_train_loader, coco_val_loader, \n",
    "                                        'detection', num_epochs=25, stage_name=\"COCO detection\")\n",
    "        print(f\"COCO detection baseline mAP: {map_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 2 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 2\n",
    "    print(\"\\n--- Evaluation after Stage 2 ---\")\n",
    "    try:\n",
    "        stage2_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 2 evaluation error: {e}\")\n",
    "        stage2_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Stage 3: ImageNet Classification\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 3: ImageNet Classification Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        top1_base = learner.train_stage(imagenet_train_loader, imagenet_val_loader, \n",
    "                                        'classification', num_epochs=20, stage_name=\"ImageNet classification\")\n",
    "        print(f\"ImageNet classification baseline Top-1: {top1_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 3 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 3\n",
    "    print(\"\\n--- Evaluation after Stage 3 (before fine-tuning) ---\")\n",
    "    try:\n",
    "        pre_finetune_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Pre-fine-tuning evaluation error: {e}\")\n",
    "        pre_finetune_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Set target metrics (allow 5% drop)\n",
    "    target_metrics = {\n",
    "        'mIoU': miou_base * 100 - 5,\n",
    "        'mAP': map_base * 100 - 5,\n",
    "        'Top1_acc': top1_base - 5\n",
    "    }\n",
    "\n",
    "    print(f\"\\nTarget metrics (baseline - 5%):\")\n",
    "    print(f\"mIoU: ≥ {target_metrics['mIoU']:.2f}%\")\n",
    "    print(f\"mAP: ≥ {target_metrics['mAP']:.2f}%\")\n",
    "    print(f\"Top-1: ≥ {target_metrics['Top1_acc']:.2f}%\")\n",
    "    \n",
    "    # Check if balanced multi-task fine-tuning is needed\n",
    "    needs_finetuning = (\n",
    "        pre_finetune_metrics['mIoU'] < target_metrics['mIoU'] or\n",
    "        pre_finetune_metrics['mAP'] < target_metrics['mAP'] or\n",
    "        pre_finetune_metrics['Top1_acc'] < target_metrics['Top1_acc']\n",
    "    )\n",
    "    \n",
    "    if needs_finetuning:\n",
    "        print(f\"\\nSome metrics are below target. Starting balanced multi-task fine-tuning...\")\n",
    "        print(f\"Current: mIoU={pre_finetune_metrics['mIoU']:.2f}%, \"\n",
    "              f\"mAP={pre_finetune_metrics['mAP']:.2f}%, \"\n",
    "              f\"Top1={pre_finetune_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Execute balanced multi-task fine-tuning\n",
    "        try:\n",
    "            improved_metrics = learner.balanced_multi_task_fine_tuning(data_loaders, target_metrics)\n",
    "            print(f\"Balanced fine-tuning completed!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fine-tuning failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            improved_metrics = pre_finetune_metrics\n",
    "    else:\n",
    "        print(f\"All metrics meet target standards. No fine-tuning needed.\")\n",
    "        improved_metrics = pre_finetune_metrics\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Final Results\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        final_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Final evaluation error: {e}\")\n",
    "        final_metrics = improved_metrics\n",
    "    \n",
    "    # Check forgetting criterion\n",
    "    base_metrics = {\n",
    "        'mIoU': miou_base * 100,\n",
    "        'mAP': map_base * 100, \n",
    "        'Top1_acc': top1_base\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        criterion_met = learner.check_forgetting_criterion(final_metrics, base_metrics)\n",
    "        print(f\"\\nForgetting criterion satisfied: {'Yes' if criterion_met else 'No'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking forgetting criterion: {e}\")\n",
    "        criterion_met = False\n",
    "    \n",
    "    # Detailed performance analysis\n",
    "    print(f\"\\nDetailed performance analysis:\")\n",
    "    try:\n",
    "        miou_change = final_metrics['mIoU'] - miou_base * 100\n",
    "        map_change = final_metrics['mAP'] - map_base * 100\n",
    "        top1_change = final_metrics['Top1_acc'] - top1_base\n",
    "        \n",
    "        print(f\"VOC mIoU: {final_metrics['mIoU']:.2f}% (baseline: {miou_base * 100:.2f}%, change: {miou_change:+.2f}%)\")\n",
    "        print(f\"COCO mAP: {final_metrics['mAP']:.2f}% (baseline: {map_base * 100:.2f}%, change: {map_change:+.2f}%)\")\n",
    "        print(f\"ImageNet Top-1: {final_metrics['Top1_acc']:.2f}% (baseline: {top1_base:.2f}%, change: {top1_change:+.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Performance analysis error: {e}\")\n",
    "        miou_change = map_change = top1_change = 0\n",
    "    \n",
    "    # Print training history\n",
    "    print(f\"\\nTraining history:\")\n",
    "    try:\n",
    "        for i, stage in enumerate(learner.training_history['stage']):\n",
    "            print(f\"{stage}: mIoU={learner.training_history['mIoU'][i]:.2f}%, \"\n",
    "                    f\"mAP={learner.training_history['mAP'][i]:.2f}%, \"\n",
    "                    f\"Top1={learner.training_history['Top1_acc'][i]:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error printing training history: {e}\")\n",
    "    \n",
    "    # Success criteria check\n",
    "    try:\n",
    "        success_criteria = {\n",
    "            'mIoU_ok': final_metrics['mIoU'] >= (miou_base * 100 - 5),\n",
    "            'mAP_ok': final_metrics['mAP'] >= (map_base * 100 - 5),\n",
    "            'Top1_ok': final_metrics['Top1_acc'] >= (top1_base - 5)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nSuccess criteria:\")\n",
    "        print(f\"mIoU ≥ {miou_base * 100 - 5:.2f}%: {'Passed' if success_criteria['mIoU_ok'] else 'Failed'}\")\n",
    "        print(f\"mAP ≥ {map_base * 100 - 5:.2f}%: {'Passed' if success_criteria['mAP_ok'] else 'Failed'}\")\n",
    "        print(f\"Top-1 ≥ {top1_base - 5:.2f}%: {'Passed' if success_criteria['Top1_ok'] else 'Failed'}\")\n",
    "        \n",
    "        overall_success = all(success_criteria.values())\n",
    "        print(f\"\\nOverall success: {'Passed' if overall_success else 'Failed'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Success criteria check error: {e}\")\n",
    "        overall_success = False\n",
    "        success_criteria = {'mIoU_ok': False, 'mAP_ok': False, 'Top1_ok': False}\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(f\"\\nPerformance comparison:\")\n",
    "    try:\n",
    "        print(f\"{'Metric':<15} {'Stage1':<10} {'Stage2':<10} {'Stage3':<10} {'Final':<10} {'Change':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        print(f\"{'mIoU (%)':<15} {stage1_metrics['mIoU']:<10.2f} {stage2_metrics['mIoU']:<10.2f} {pre_finetune_metrics['mIoU']:<10.2f} {final_metrics['mIoU']:<10.2f} {miou_change:<+10.2f}\")\n",
    "        print(f\"{'mAP (%)':<15} {stage1_metrics['mAP']:<10.2f} {stage2_metrics['mAP']:<10.2f} {pre_finetune_metrics['mAP']:<10.2f} {final_metrics['mAP']:<10.2f} {map_change:<+10.2f}\")\n",
    "        print(f\"{'Top-1 (%)':<15} {stage1_metrics['Top1_acc']:<10.2f} {stage2_metrics['Top1_acc']:<10.2f} {pre_finetune_metrics['Top1_acc']:<10.2f} {final_metrics['Top1_acc']:<10.2f} {top1_change:<+10.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Performance comparison error: {e}\")\n",
    "    \n",
    "    \n",
    "    # Plot results\n",
    "    print(\"\\nPlotting training results...\")\n",
    "    try:\n",
    "        learner.plot_loss_curves('balanced_training_losses.png')\n",
    "        print(\"Loss curves saved successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting error: {e}\")\n",
    "    \n",
    "    \n",
    "    # Return results\n",
    "    try:\n",
    "        return {\n",
    "            'final_metrics': final_metrics,\n",
    "            'base_metrics': base_metrics,\n",
    "            'success': overall_success,\n",
    "            'learner': learner,\n",
    "            'stage_progression': {\n",
    "                'stage1': stage1_metrics,\n",
    "                'stage2': stage2_metrics,\n",
    "                'stage3': pre_finetune_metrics,\n",
    "                'final': final_metrics\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating return object: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting balanced multi-task learning...\")\n",
    "    results = main()\n",
    "    if results:\n",
    "        print(\"Training completed successfully!\")\n",
    "        print(f\"\\nFinal summary:\")\n",
    "        print(f\"mIoU: {results['final_metrics']['mIoU']:.2f}%\")\n",
    "        print(f\"mAP: {results['final_metrics']['mAP']:.2f}%\") \n",
    "        print(f\"Top-1: {results['final_metrics']['Top1_acc']:.2f}%\")\n",
    "        print(f\"Overall success: {'Passed' if results['success'] else 'Failed'}\")\n",
    "    else:\n",
    "        print(\"Training failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
