{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e19cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import traceback\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Fix all random seeds\n",
    "def set_random_seed(seed=42):\n",
    "    \"\"\"Set all random seeds to ensure reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Fix Python hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"All random seeds set to: {seed}\")\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    \"\"\"COCO Detection Dataset\"\"\"\n",
    "    def __init__(self, json_file, img_dir, transform=None):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                self.data = json.load(f)\n",
    "            print(f\"✅ Successfully loaded COCO data: {json_file}\")\n",
    "            \n",
    "            self.images = self.data['images']\n",
    "            self.annotations = self.data.get('annotations', [])\n",
    "            \n",
    "            # Process categories\n",
    "            self.categories = self.data.get('categories', [])\n",
    "            self.cat_id_to_idx = {}\n",
    "            for idx, cat in enumerate(self.categories):\n",
    "                self.cat_id_to_idx[cat['id']] = idx\n",
    "            \n",
    "            # Build image to annotation mapping\n",
    "            self.img_to_anns = defaultdict(list)\n",
    "            for ann in self.annotations:\n",
    "                self.img_to_anns[ann['image_id']].append(ann)\n",
    "            \n",
    "            print(f\"Found {len(self.images)} images and {len(self.annotations)} annotations\")\n",
    "            print(f\"Number of categories: {len(self.categories)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading COCO JSON file {json_file}: {e}\")\n",
    "            # Create dummy data\n",
    "            self.images = [{'id': i, 'file_name': f'dummy_{i}.jpg'} for i in range(50)]\n",
    "            self.annotations = []\n",
    "            self.img_to_anns = defaultdict(list)\n",
    "            self.categories = [{'id': i, 'name': f'class_{i}'} for i in range(80)]\n",
    "            self.cat_id_to_idx = {i: i for i in range(80)}\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_info = self.images[idx]\n",
    "            img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "            \n",
    "            # Load image\n",
    "            if not os.path.exists(img_path):\n",
    "                # Create fixed dummy image instead of random image\n",
    "                image = Image.new('RGB', (224, 224), color=(128, 128, 128))\n",
    "            else:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Get annotations for this image\n",
    "            img_id = img_info['id']\n",
    "            anns = self.img_to_anns[img_id]\n",
    "            \n",
    "            # Create multi-label target\n",
    "            target = torch.zeros(80)\n",
    "            \n",
    "            for ann in anns:\n",
    "                cat_id = ann['category_id']\n",
    "                if cat_id in self.cat_id_to_idx:\n",
    "                    class_idx = self.cat_id_to_idx[cat_id]\n",
    "                    if class_idx < 80:\n",
    "                        target[class_idx] = 1.0\n",
    "            \n",
    "            # If no annotations, give a fixed label to avoid all-zero targets\n",
    "            if target.sum() == 0:\n",
    "                target[idx % 80] = 1.0  # Give fixed label based on index\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, target\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"COCO data loading error idx={idx}: {e}\")\n",
    "            # Return fixed dummy data\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_target = torch.zeros(80)\n",
    "            dummy_target[idx % 80] = 1.0\n",
    "            return dummy_image, dummy_target\n",
    "\n",
    "class VOCSegmentationDataset(Dataset):\n",
    "    \"\"\"VOC Segmentation Dataset - Debug version\"\"\"\n",
    "    def __init__(self, json_file, base_dir='./VOC_subset', transform=None, seg_transform=None):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                self.data = json.load(f)\n",
    "            print(f\"Successfully loaded VOC data: {len(self.data)} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading VOC JSON file {json_file}: {e}\")\n",
    "            # Create dummy data\n",
    "            self.data = [\n",
    "                {'image': f'dummy_image_{i}.jpg', 'segmentation': f'dummy_mask_{i}.png'}\n",
    "                for i in range(50)\n",
    "            ]\n",
    "        \n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.seg_transform = seg_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.data[idx]\n",
    "            \n",
    "            # Load image\n",
    "            img_path = os.path.join(self.base_dir, item['image'])\n",
    "            if not os.path.exists(img_path):\n",
    "                # Create fixed dummy image\n",
    "                image = Image.new('RGB', (224, 224), color=(64, 128, 192))\n",
    "            else:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Load segmentation mask\n",
    "            seg_path = os.path.join(self.base_dir, item['segmentation'])\n",
    "            if not os.path.exists(seg_path):\n",
    "                # Create fixed dummy mask\n",
    "                mask_array = np.zeros((224, 224), dtype=np.uint8)\n",
    "                # Create a fixed rectangular region as foreground\n",
    "                mask_array[50:150, 50:150] = 255\n",
    "                mask = Image.fromarray(mask_array, mode='L')\n",
    "            else:\n",
    "                mask = Image.open(seg_path).convert('L')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            if self.seg_transform:\n",
    "                mask = self.seg_transform(mask)\n",
    "            else:\n",
    "                mask = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor()\n",
    "                ])(mask)\n",
    "            \n",
    "            return image, mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"VOC data loading error idx={idx}: {e}\")\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_mask = torch.ones(1, 224, 224) * 0.5  # Fixed value instead of random\n",
    "            return dummy_image, dummy_mask\n",
    "\n",
    "class ImageNetDataset(Dataset):\n",
    "    \"\"\"ImageNet Classification Dataset\"\"\"\n",
    "    def __init__(self, txt_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    img_path = parts[0]\n",
    "                    try:\n",
    "                        label = int(parts[1])\n",
    "                        # Update: Change from 999 to 29 for 30 classes (0-29)\n",
    "                        label = max(0, min(label, 29))  # Changed from min(label, 999)\n",
    "                        self.samples.append((img_path, label))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                \n",
    "        print(f\"Successfully loaded ImageNet data: {len(self.samples)} samples\")\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path, label = self.samples[idx]\n",
    "            full_path = os.path.join(self.img_dir, img_path)\n",
    "            \n",
    "            if not os.path.exists(full_path):\n",
    "                # Create fixed dummy image with 30-class compatible colors\n",
    "                image = Image.new('RGB', (224, 224), color=(label % 256, (label*2) % 256, (label*3) % 256))\n",
    "            else:\n",
    "                image = Image.open(full_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet data loading error idx={idx}: {e}\")\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            dummy_label = idx % 30  # Changed from % 1000\n",
    "            return dummy_image, dummy_label\n",
    "\n",
    "class BalancedMultiTaskModel(nn.Module):\n",
    "    \"\"\"Balanced Multi-Task Model - Improved version\"\"\"\n",
    "    def __init__(self, num_classes_det=80, num_classes_cls=1000):\n",
    "        super(BalancedMultiTaskModel, self).__init__()\n",
    "        \n",
    "        print(\"Initializing multi-task model...\")\n",
    "        \n",
    "        # Use EfficientNet-B0 as shared backbone\n",
    "        try:\n",
    "            backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "            print(\"Using pre-trained EfficientNet-B0\")\n",
    "        except:\n",
    "            try:\n",
    "                backbone = models.efficientnet_b0(pretrained=True)\n",
    "                print(\"Using pre-trained EfficientNet-B0 (legacy)\")\n",
    "            except:\n",
    "                backbone = models.efficientnet_b0(pretrained=False)\n",
    "                print(\"Using non-pre-trained EfficientNet-B0\")\n",
    "            \n",
    "        self.feature_extractor = backbone.features\n",
    "        \n",
    "        # Shared feature processing layer\n",
    "        self.shared_conv = nn.Sequential(\n",
    "            nn.Conv2d(1280, 320, kernel_size=1),\n",
    "            nn.BatchNorm2d(320),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.1)\n",
    "        )\n",
    "        \n",
    "        # Segmentation branch\n",
    "        self.seg_branch = nn.Sequential(\n",
    "            nn.Conv2d(320, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(32, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        # Detection branch - Multi-scale features\n",
    "        self.det_global_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.det_spatial_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((3, 3)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320 * 9, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.det_classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes_det)\n",
    "        )\n",
    "        \n",
    "        # Classification branch - Enhanced version\n",
    "        self.cls_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 512),  # Increased capacity\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes_cls)\n",
    "        )\n",
    "\n",
    "        # Calculate parameter count\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Total parameters: {total_params / 1e6:.2f}M\")\n",
    "        \n",
    "        if total_params >= 8e6:\n",
    "            print(f\"Warning: Model has {total_params / 1e6:.2f}M parameters, approaching 8M limit\")\n",
    "        else:\n",
    "            print(f\"Parameter count within limit: {total_params / 1e6:.2f}M < 8M\")\n",
    "    \n",
    "    def forward(self, x, task='classification'):\n",
    "        features = self.feature_extractor(x)\n",
    "        shared_features = self.shared_conv(features)\n",
    "        \n",
    "        if task == 'segmentation':\n",
    "            return self.seg_branch(shared_features)\n",
    "        elif task == 'detection':\n",
    "            global_features = self.det_global_branch(shared_features)\n",
    "            spatial_features = self.det_spatial_branch(shared_features)\n",
    "            combined = torch.cat([global_features, spatial_features], dim=1)\n",
    "            return self.det_classifier(combined)\n",
    "        elif task == 'classification':\n",
    "            return self.cls_branch(shared_features)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "def compute_ap(pred_scores, true_labels):\n",
    "    \"\"\"Compute Average Precision for a single class\"\"\"\n",
    "    if len(pred_scores) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    sorted_indices = np.argsort(pred_scores)[::-1]\n",
    "    sorted_scores = pred_scores[sorted_indices]\n",
    "    sorted_labels = true_labels[sorted_indices]\n",
    "    \n",
    "    tp = np.cumsum(sorted_labels)\n",
    "    fp = np.cumsum(1 - sorted_labels)\n",
    "    \n",
    "    num_positives = np.sum(true_labels)\n",
    "    if num_positives == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / num_positives\n",
    "    \n",
    "    # 11-point interpolation\n",
    "    ap = 0.0\n",
    "    for t in np.arange(0, 1.1, 0.1):\n",
    "        if np.sum(recall >= t) == 0:\n",
    "            p = 0\n",
    "        else:\n",
    "            p = np.max(precision[recall >= t])\n",
    "        ap += p / 11\n",
    "    \n",
    "    return ap\n",
    "\n",
    "def compute_map(predictions, targets, num_classes=80):\n",
    "    \"\"\"Compute mAP\"\"\"\n",
    "    if predictions.shape[0] == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    aps = []\n",
    "    valid_classes = 0\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        pred_scores = predictions[:, class_idx]\n",
    "        true_labels = targets[:, class_idx]\n",
    "        \n",
    "        if np.sum(true_labels) > 0:  # Only compute for classes with positive samples\n",
    "            ap = compute_ap(pred_scores, true_labels)\n",
    "            aps.append(ap)\n",
    "            valid_classes += 1\n",
    "    \n",
    "    if valid_classes == 0:\n",
    "        print(\"Warning: No valid classes for mAP computation\")\n",
    "        return 0.0\n",
    "        \n",
    "    mean_ap = np.mean(aps)\n",
    "    print(f\"mAP computation: {valid_classes} valid classes, average AP: {mean_ap:.4f}\")\n",
    "    return mean_ap\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class EnhancedEWC:\n",
    "    \"\"\"Enhanced Elastic Weight Consolidation\"\"\"\n",
    "    def __init__(self, model, dataset_loader, task_type='classification', importance=2000):\n",
    "        self.model = model\n",
    "        # Increase importance for classification tasks\n",
    "        if task_type == 'classification':\n",
    "            self.importance = importance * 2  # Increase to 4000\n",
    "            print(f\"Classification task EWC importance set to: {self.importance}\")\n",
    "        else:\n",
    "            self.importance = importance\n",
    "            \n",
    "        self.task_type = task_type\n",
    "        self.params = {n: p.clone().detach() for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self.fisher = self._compute_fisher_information(dataset_loader)\n",
    "    \n",
    "    def _compute_fisher_information(self, dataset_loader):\n",
    "        \"\"\"Compute Fisher Information Matrix\"\"\"\n",
    "        fisher = {}\n",
    "        self.model.eval()\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        \n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                fisher[n] = torch.zeros_like(p)\n",
    "        \n",
    "        print(f\"Computing Fisher Information Matrix, task type: {self.task_type}\")\n",
    "        \n",
    "        num_batches = 0\n",
    "        max_batches = min(30, len(dataset_loader))  # Reduce batch count to save memory\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(dataset_loader):\n",
    "            if batch_idx >= max_batches:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                data = data.cuda() if torch.cuda.is_available() else data\n",
    "                target = target.cuda() if torch.cuda.is_available() else target\n",
    "                \n",
    "                # Reduce batch size\n",
    "                if data.size(0) > 2:\n",
    "                    data = data[:2]\n",
    "                    target = target[:2]\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                \n",
    "                if self.task_type == 'classification':\n",
    "                    output = self.model(data, task='classification')\n",
    "                    loss = F.cross_entropy(output, target)\n",
    "                elif self.task_type == 'detection':\n",
    "                    output = self.model(data, task='detection')\n",
    "                    loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                elif self.task_type == 'segmentation':\n",
    "                    output = self.model(data, task='segmentation')\n",
    "                    if target.dim() == 4 and target.size(1) == 1:\n",
    "                        target = target.squeeze(1)\n",
    "                    if output.dim() == 4 and output.size(1) == 1:\n",
    "                        output = output.squeeze(1)\n",
    "                    loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for n, p in self.model.named_parameters():\n",
    "                        if p.requires_grad and p.grad is not None and n in fisher:\n",
    "                            fisher[n] += p.grad.pow(2).detach()\n",
    "                \n",
    "                num_batches += 1\n",
    "                self.model.zero_grad()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Fisher computation batch {batch_idx} error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Normalize Fisher information\n",
    "        for n in fisher:\n",
    "            if num_batches > 0:\n",
    "                fisher[n] = fisher[n] / num_batches + 1e-8\n",
    "            else:\n",
    "                fisher[n] = torch.ones_like(fisher[n]) * 1e-8\n",
    "        \n",
    "        print(f\"Fisher computation completed, processed {num_batches} batches\")\n",
    "        return fisher\n",
    "    \n",
    "    def penalty(self):\n",
    "        \"\"\"Compute EWC penalty term\"\"\"\n",
    "        loss = 0\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad and n in self.fisher and n in self.params:\n",
    "                param_diff = (p - self.params[n]).pow(2)\n",
    "                fisher_weighted = self.fisher[n] * param_diff\n",
    "                loss += fisher_weighted.sum()\n",
    "        \n",
    "        return self.importance * loss\n",
    "\n",
    "class BalancedContinualLearner:\n",
    "    \"\"\"Balanced Continual Learner - Debug improved version\"\"\"\n",
    "    def __init__(self, model, learning_rate=0.0002):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, T_0=10, T_mult=2)\n",
    "        self.ewc_tasks = []\n",
    "        self.task_snapshots = []\n",
    "        self.task_best_metrics = {}\n",
    "        self.tasks_completed = 0\n",
    "        \n",
    "        self.focal_loss = FocalLoss(alpha=1, gamma=2)\n",
    "        \n",
    "        # Training history\n",
    "        self.training_history = {\n",
    "            'stage': [],\n",
    "            'mIoU': [],\n",
    "            'mAP': [],\n",
    "            'Top1_acc': []\n",
    "        }\n",
    "        \n",
    "        self.loss_history = {\n",
    "            'train_losses': [],\n",
    "            'val_losses': [],\n",
    "            'stage_names': []\n",
    "        }\n",
    "        \n",
    "        print(\"Balanced continual learner initialized\")\n",
    "    \n",
    "    def compute_iou(self, pred_mask, true_mask, threshold=0.5):\n",
    "        \"\"\"Compute IoU metric\"\"\"\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                pred_binary = (torch.sigmoid(pred_mask) > threshold).float()\n",
    "                true_binary = true_mask.float()\n",
    "                \n",
    "                intersection = (pred_binary * true_binary).sum()\n",
    "                union = pred_binary.sum() + true_binary.sum() - intersection\n",
    "                \n",
    "                if union == 0:\n",
    "                    return 1.0 if intersection == 0 else 0.0\n",
    "                return (intersection / (union + 1e-8)).item()\n",
    "        except Exception as e:\n",
    "            print(f\"IoU computation error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def save_task_snapshot(self, task_name, best_metric):\n",
    "        \"\"\"Save task snapshot\"\"\"\n",
    "        snapshot = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            snapshot[name] = param.clone().detach()\n",
    "        self.task_snapshots.append(snapshot)\n",
    "        self.task_best_metrics[task_name] = best_metric\n",
    "        print(f\"Saved task snapshot: {task_name}, metric: {best_metric:.4f}\")\n",
    "    \n",
    "    def get_adaptive_regularization_loss(self, current_task):\n",
    "        \"\"\"Adaptive regularization loss\"\"\"\n",
    "        reg_loss = 0\n",
    "        \n",
    "        # EWC regularization\n",
    "        if len(self.ewc_tasks) > 0:\n",
    "            ewc_weight = 0.001  # Reduce EWC weight\n",
    "            for ewc_task in self.ewc_tasks:\n",
    "                reg_loss += ewc_weight * ewc_task.penalty()\n",
    "        \n",
    "        # L2 regularization\n",
    "        if len(self.task_snapshots) > 0:\n",
    "            l2_loss = 0\n",
    "            for snapshot in self.task_snapshots:\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if name in snapshot:\n",
    "                        l2_loss += torch.norm(param - snapshot[name]) ** 2\n",
    "            reg_loss += 0.0001 * l2_loss  # Reduce L2 weight\n",
    "        \n",
    "        return reg_loss\n",
    "    \n",
    "    def dedicated_classification_fine_tuning(self, data_loaders, target_top1, max_epochs=10):\n",
    "        \"\"\"Dedicated classification fine-tuning\"\"\"\n",
    "        print(f\"\\nStarting dedicated classification fine-tuning\")\n",
    "        print(f\"Target Top-1 accuracy: {target_top1:.2f}%\")\n",
    "        \n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        \n",
    "        # Save original learning rate\n",
    "        original_lr = self.optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Use higher learning rate for classification fine-tuning\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = 0.0005  # Higher learning rate\n",
    "        \n",
    "        best_top1 = 0\n",
    "        best_model_state = None\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(f\"\\n--- Classification Fine-tuning Epoch {epoch+1}/{max_epochs} ---\")\n",
    "            \n",
    "            # Training\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(imagenet_train_loader):\n",
    "                if batch_idx >= 15:  # Limit batch count\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(data, task='classification')\n",
    "                    \n",
    "                    # Classification loss\n",
    "                    cls_loss = F.cross_entropy(output, target, label_smoothing=0.1)\n",
    "                    \n",
    "                    # Reduce regularization strength\n",
    "                    total_loss = cls_loss\n",
    "                    if len(self.ewc_tasks) > 0:\n",
    "                        reg_loss = 0.00001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                        total_loss += reg_loss\n",
    "                    \n",
    "                    total_loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += total_loss.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        acc = (predicted == target).float().mean().item()\n",
    "                        epoch_acc += acc\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Classification training batch error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Validation\n",
    "            if batch_count > 0:\n",
    "                avg_loss = epoch_loss / batch_count\n",
    "                avg_acc = epoch_acc / batch_count\n",
    "                \n",
    "                try:\n",
    "                    val_top1, _ = self.evaluate(imagenet_val_loader, 'classification')\n",
    "                    print(f\"Epoch {epoch+1}: Train loss={avg_loss:.4f}, Train acc={avg_acc:.4f}, Val Top-1={val_top1:.2f}%\")\n",
    "                    \n",
    "                    if val_top1 > best_top1:\n",
    "                        best_top1 = val_top1\n",
    "                        best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                        patience_counter = 0\n",
    "                        print(f\"New best classification accuracy: {best_top1:.2f}%\")\n",
    "                        \n",
    "                        if val_top1 >= target_top1:\n",
    "                            print(f\"Target accuracy reached! Stopping fine-tuning.\")\n",
    "                            break\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                        if patience_counter >= patience:\n",
    "                            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Validation error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(f\"Restored best classification model Top-1: {best_top1:.2f}%\")\n",
    "        \n",
    "        # Restore original learning rate\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = original_lr\n",
    "        \n",
    "        return best_top1\n",
    "    \n",
    "    def balanced_multi_task_fine_tuning(self, data_loaders, target_metrics, max_epochs=15):\n",
    "        \"\"\"Balanced multi-task fine-tuning - Improved version\"\"\"\n",
    "        print(f\"\\n === Balanced Multi-Task Fine-Tuning ===\")\n",
    "        \n",
    "        # Remove extra safety margins, use original targets\n",
    "        enhanced_target_metrics = {\n",
    "            'mIoU': target_metrics.get('mIoU', 0),\n",
    "            'mAP': target_metrics.get('mAP', 0),\n",
    "            'Top1_acc': target_metrics.get('Top1_acc', 0)  # No extra margin\n",
    "        }\n",
    "        \n",
    "        print(f\"Target metrics:\")\n",
    "        print(f\"mIoU: ≥ {enhanced_target_metrics['mIoU']:.2f}%\")\n",
    "        print(f\"mAP: ≥ {enhanced_target_metrics['mAP']:.2f}%\")\n",
    "        print(f\"Top-1: ≥ {enhanced_target_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Get current performance\n",
    "        current_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "        print(f\"Current metrics: mIoU={current_metrics['mIoU']:.2f}%, \"\n",
    "            f\"mAP={current_metrics['mAP']:.2f}%, Top1={current_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Check which tasks need improvement\n",
    "        need_improvement = {\n",
    "            'segmentation': current_metrics['mIoU'] < enhanced_target_metrics['mIoU'],\n",
    "            'detection': current_metrics['mAP'] < enhanced_target_metrics['mAP'],\n",
    "            'classification': current_metrics['Top1_acc'] < enhanced_target_metrics['Top1_acc']\n",
    "        }\n",
    "        \n",
    "        tasks_to_improve = [task for task, need in need_improvement.items() if need]\n",
    "        \n",
    "        if not tasks_to_improve:\n",
    "            print(\"All tasks have reached target metrics!\")\n",
    "            return current_metrics\n",
    "        \n",
    "        print(f\"Tasks needing improvement: {tasks_to_improve}\")\n",
    "        \n",
    "        # If only classification task needs improvement, use dedicated classification fine-tuning\n",
    "        if tasks_to_improve == ['classification']:\n",
    "            print(\"Only classification task needs improvement, using dedicated classification fine-tuning\")\n",
    "            final_top1 = self.dedicated_classification_fine_tuning(\n",
    "                data_loaders, enhanced_target_metrics['Top1_acc'], max_epochs=15\n",
    "            )\n",
    "            \n",
    "            # Re-evaluate all tasks\n",
    "            final_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "            return final_metrics\n",
    "        \n",
    "        # Set fine-tuning learning rate\n",
    "        original_lr = self.optimizer.param_groups[0]['lr']\n",
    "        finetune_lr = original_lr * 0.5  # Conservative learning rate\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = finetune_lr\n",
    "        \n",
    "        print(f\"Set fine-tuning learning rate: {finetune_lr:.8f}\")\n",
    "        \n",
    "        # Prepare data loaders\n",
    "        voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "        coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        \n",
    "        best_combined_score = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(f\"\\n--- Multi-task Fine-tuning Epoch {epoch+1}/{max_epochs} ---\")\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_losses = {'seg': [], 'det': [], 'cls': []}\n",
    "            epoch_metrics = {'seg': [], 'det': [], 'cls': []}\n",
    "            \n",
    "            # Create data iterators\n",
    "            try:\n",
    "                seg_iter = iter(voc_train_loader) if 'segmentation' in tasks_to_improve else None\n",
    "                det_iter = iter(coco_train_loader) if 'detection' in tasks_to_improve else None\n",
    "                cls_iter = iter(imagenet_train_loader) if 'classification' in tasks_to_improve else None\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating iterators: {e}\")\n",
    "                break\n",
    "            \n",
    "            # Calculate training batches\n",
    "            available_lengths = []\n",
    "            if seg_iter: available_lengths.append(len(voc_train_loader))\n",
    "            if det_iter: available_lengths.append(len(coco_train_loader))\n",
    "            if cls_iter: available_lengths.append(len(imagenet_train_loader))\n",
    "            \n",
    "            if not available_lengths:\n",
    "                print(\"No tasks need improvement\")\n",
    "                break\n",
    "                \n",
    "            train_batches_per_task = min(min(available_lengths), 15)  # Limit batch count\n",
    "            \n",
    "            # Alternating training for all tasks needing improvement\n",
    "            for batch_idx in range(train_batches_per_task):\n",
    "                \n",
    "                # 1. Segmentation training\n",
    "                if 'segmentation' in tasks_to_improve and seg_iter:\n",
    "                    try:\n",
    "                        data, target = next(seg_iter)\n",
    "                        if torch.cuda.is_available():\n",
    "                            data, target = data.cuda(), target.cuda()\n",
    "                        \n",
    "                        self.optimizer.zero_grad()\n",
    "                        output = self.model(data, task='segmentation')\n",
    "                        \n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        seg_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1e-6) / (union + 1e-6)\n",
    "                        \n",
    "                        seg_total_loss = seg_loss + dice_loss\n",
    "                        \n",
    "                        # Less regularization\n",
    "                        if len(self.ewc_tasks) > 0:\n",
    "                            reg_loss = 0.0001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                            seg_total_loss += reg_loss\n",
    "                        \n",
    "                        seg_total_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                        self.optimizer.step()\n",
    "                        \n",
    "                        epoch_losses['seg'].append(seg_total_loss.item())\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            iou = self.compute_iou(output, target)\n",
    "                            epoch_metrics['seg'].append(iou)\n",
    "                        \n",
    "                    except (StopIteration, Exception) as e:\n",
    "                        continue\n",
    "                \n",
    "                # 2. Detection training\n",
    "                if 'detection' in tasks_to_improve and det_iter:\n",
    "                    try:\n",
    "                        data, target = next(det_iter)\n",
    "                        if torch.cuda.is_available():\n",
    "                            data, target = data.cuda(), target.cuda()\n",
    "                        \n",
    "                        self.optimizer.zero_grad()\n",
    "                        output = self.model(data, task='detection')\n",
    "                        \n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        det_total_loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        # Less regularization\n",
    "                        if len(self.ewc_tasks) > 0:\n",
    "                            reg_loss = 0.0001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                            det_total_loss += reg_loss\n",
    "                        \n",
    "                        det_total_loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                        self.optimizer.step()\n",
    "                        \n",
    "                        epoch_losses['det'].append(det_total_loss.item())\n",
    "                        \n",
    "                        with torch.no_grad():\n",
    "                            pred_binary = torch.sigmoid(output) > 0.5\n",
    "                            acc = (pred_binary == target.bool()).float().mean().item()\n",
    "                            epoch_metrics['det'].append(acc)\n",
    "                        \n",
    "                    except (StopIteration, Exception) as e:\n",
    "                        continue\n",
    "                \n",
    "                # 3. Classification training - Special handling\n",
    "                if 'classification' in tasks_to_improve and cls_iter:\n",
    "                    # Train classification task twice to enhance learning\n",
    "                    for _ in range(2):\n",
    "                        try:\n",
    "                            data, target = next(cls_iter)\n",
    "                            if torch.cuda.is_available():\n",
    "                                data, target = data.cuda(), target.cuda()\n",
    "                            \n",
    "                            self.optimizer.zero_grad()\n",
    "                            output = self.model(data, task='classification')\n",
    "                            \n",
    "                            cls_loss = F.cross_entropy(output, target, label_smoothing=0.1)\n",
    "                            \n",
    "                            # Minimal regularization\n",
    "                            if len(self.ewc_tasks) > 0:\n",
    "                                reg_loss = 0.00001 * sum([ewc.penalty() for ewc in self.ewc_tasks])\n",
    "                                cls_loss += reg_loss\n",
    "                            \n",
    "                            cls_loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                            self.optimizer.step()\n",
    "                            \n",
    "                            epoch_losses['cls'].append(cls_loss.item())\n",
    "                            \n",
    "                            with torch.no_grad():\n",
    "                                _, predicted = torch.max(output, 1)\n",
    "                                acc = (predicted == target).float().mean().item()\n",
    "                                epoch_metrics['cls'].append(acc)\n",
    "                            \n",
    "                        except (StopIteration, Exception) as e:\n",
    "                            break\n",
    "            \n",
    "            # Calculate epoch average metrics\n",
    "            avg_seg_metric = np.mean(epoch_metrics['seg']) if epoch_metrics['seg'] else 0\n",
    "            avg_det_metric = np.mean(epoch_metrics['det']) if epoch_metrics['det'] else 0\n",
    "            avg_cls_metric = np.mean(epoch_metrics['cls']) if epoch_metrics['cls'] else 0\n",
    "            \n",
    "            print(f\"Epoch {epoch+1} training metrics:\")\n",
    "            if epoch_metrics['seg']:\n",
    "                print(f\"  Segmentation IoU: {avg_seg_metric:.4f}\")\n",
    "            if epoch_metrics['det']:\n",
    "                print(f\"  Detection accuracy: {avg_det_metric:.4f}\")\n",
    "            if epoch_metrics['cls']:\n",
    "                print(f\"  Classification accuracy: {avg_cls_metric:.4f}\")\n",
    "            \n",
    "            # Validate all tasks\n",
    "            try:\n",
    "                val_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "                print(f\"Epoch {epoch+1} validation metrics:\")\n",
    "                print(f\"  mIoU: {val_metrics['mIoU']:.2f}%\")\n",
    "                print(f\"  mAP: {val_metrics['mAP']:.2f}%\")\n",
    "                print(f\"  Top-1: {val_metrics['Top1_acc']:.2f}%\")\n",
    "                \n",
    "                # Calculate combined score\n",
    "                combined_score = (val_metrics['mIoU'] + val_metrics['mAP'] + val_metrics['Top1_acc']) / 3\n",
    "                \n",
    "                if combined_score > best_combined_score:\n",
    "                    best_combined_score = combined_score\n",
    "                    best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    print(f\"New best combined score: {combined_score:.2f}\")\n",
    "                    \n",
    "                    # Check if all tasks meet targets\n",
    "                    all_targets_met = (\n",
    "                        val_metrics['mIoU'] >= enhanced_target_metrics['mIoU'] and\n",
    "                        val_metrics['mAP'] >= enhanced_target_metrics['mAP'] and\n",
    "                        val_metrics['Top1_acc'] >= enhanced_target_metrics['Top1_acc']\n",
    "                    )\n",
    "                    \n",
    "                    if all_targets_met:\n",
    "                        print(f\"All target metrics achieved! Stopping fine-tuning.\")\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Validation error epoch {epoch+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(\"Restored best fine-tuned model\")\n",
    "        \n",
    "        # Restore original learning rate\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = original_lr\n",
    "        \n",
    "        # Final evaluation\n",
    "        try:\n",
    "            final_metrics = self.evaluate_all_tasks(data_loaders)\n",
    "            print(f\"\\nFinal fine-tuning results:\")\n",
    "            print(f\"mIoU: {final_metrics['mIoU']:.2f}% (target: ≥{target_metrics.get('mIoU', 0):.2f}%)\")\n",
    "            print(f\"mAP: {final_metrics['mAP']:.2f}% (target: ≥{target_metrics.get('mAP', 0):.2f}%)\")\n",
    "            print(f\"Top-1: {final_metrics['Top1_acc']:.2f}% (target: ≥{enhanced_target_metrics['Top1_acc']:.2f}%)\")\n",
    "            \n",
    "            return final_metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Final evaluation error: {e}\")\n",
    "            return current_metrics\n",
    "    \n",
    "    def train_stage(self, train_loader, val_loader, task_type, num_epochs=30, stage_name=\"\"):\n",
    "        \"\"\"Training stage - Improved version\"\"\"\n",
    "        print(f\"\\n=== Training Stage: {stage_name} ===\")\n",
    "        print(f\"Task type: {task_type}\")\n",
    "        \n",
    "        # Adjust parameters based on task type\n",
    "        if task_type == 'detection':\n",
    "            num_epochs = 25  # Reduce epoch count\n",
    "            patience = 15\n",
    "        elif task_type == 'segmentation':\n",
    "            num_epochs = 20\n",
    "            patience = 12\n",
    "        else:  # classification\n",
    "            num_epochs = 20\n",
    "            patience = 10\n",
    "        \n",
    "        print(f\"Set {num_epochs} epochs, early stopping patience: {patience}\")\n",
    "        \n",
    "        best_metric = 0\n",
    "        best_model_state = None\n",
    "        stage_train_losses = []\n",
    "        stage_val_losses = []\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Learning rate adjustment\n",
    "        if self.tasks_completed > 0:\n",
    "            reduction_factor = 0.95 ** self.tasks_completed  # Gentler decay\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] *= reduction_factor\n",
    "            print(f\"Adjusted learning rate to: {self.optimizer.param_groups[0]['lr']:.8f}\")\n",
    "        \n",
    "        # Ensure all parameters are trainable\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad_(True)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            train_metrics = []\n",
    "            batch_count = 0\n",
    "            \n",
    "            # Limit batches per epoch to save time\n",
    "            max_batches_per_epoch = min(len(train_loader), 50)\n",
    "            \n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", total=max_batches_per_epoch)\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "                if batch_idx >= max_batches_per_epoch:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    output = self.model(data, task=task_type)\n",
    "                    \n",
    "                    # Calculate task-specific loss\n",
    "                    if task_type == 'classification':\n",
    "                        task_loss = F.cross_entropy(output, target)\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        acc = (predicted == target).float().mean().item()\n",
    "                        train_metrics.append(acc)\n",
    "                        \n",
    "                    elif task_type == 'detection':\n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        task_loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        pred_binary = torch.sigmoid(output) > 0.5\n",
    "                        acc = (pred_binary == target.bool()).float().mean().item()\n",
    "                        train_metrics.append(acc)\n",
    "                        \n",
    "                    elif task_type == 'segmentation':\n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1e-6) / (union + 1e-6)\n",
    "                        \n",
    "                        task_loss = bce_loss + dice_loss\n",
    "                        \n",
    "                        iou = self.compute_iou(output, target)\n",
    "                        train_metrics.append(iou)\n",
    "                    \n",
    "                    # Add regularization\n",
    "                    total_loss_val = task_loss\n",
    "                    if len(self.ewc_tasks) > 0 or len(self.task_snapshots) > 0:\n",
    "                        reg_loss = self.get_adaptive_regularization_loss(task_type)\n",
    "                        total_loss_val += reg_loss\n",
    "                    \n",
    "                    total_loss_val.backward()\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    total_loss += total_loss_val.item()\n",
    "                    batch_count += 1\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    avg_loss = total_loss / batch_count\n",
    "                    avg_metric = np.mean(train_metrics) if train_metrics else 0\n",
    "                    progress_bar.set_postfix({'Loss': f'{avg_loss:.4f}', 'Metric': f'{avg_metric:.4f}'})\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Training batch {batch_idx} error: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            progress_bar.close()\n",
    "            \n",
    "            # Validation\n",
    "            try:\n",
    "                val_metric, val_loss = self.evaluate(val_loader, task_type)\n",
    "            except Exception as e:\n",
    "                print(f\"Validation stage error: {e}\")\n",
    "                val_metric, val_loss = 0.0, 1.0\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            if epoch % 5 == 0 and epoch > 0:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Record and check early stopping\n",
    "            if batch_count > 0:\n",
    "                avg_train_loss = total_loss / batch_count\n",
    "                stage_train_losses.append(avg_train_loss)\n",
    "                stage_val_losses.append(val_loss)\n",
    "                \n",
    "                avg_train_metric = np.mean(train_metrics) if train_metrics else 0\n",
    "                print(f\"Epoch {epoch+1}: Loss={avg_train_loss:.4f}, \"\n",
    "                      f\"Train metric={avg_train_metric:.4f}, Val metric={val_metric:.4f}\")\n",
    "                \n",
    "                if val_metric > best_metric:\n",
    "                    best_metric = val_metric\n",
    "                    best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                    patience_counter = 0\n",
    "                    print(f\"New best {task_type} metric: {best_metric:.4f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "        \n",
    "        # Restore best model\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(\"Restored best model state\")\n",
    "        \n",
    "        # Save snapshot\n",
    "        self.save_task_snapshot(stage_name, best_metric)\n",
    "        \n",
    "        # Record history\n",
    "        self.loss_history['train_losses'].append(stage_train_losses)\n",
    "        self.loss_history['val_losses'].append(stage_val_losses)\n",
    "        self.loss_history['stage_names'].append(stage_name)\n",
    "        \n",
    "        # Record metrics\n",
    "        self.training_history['stage'].append(stage_name)\n",
    "        if task_type == 'segmentation':\n",
    "            self.training_history['mIoU'].append(best_metric * 100)\n",
    "            self.training_history['mAP'].append(0)\n",
    "            self.training_history['Top1_acc'].append(0)\n",
    "        elif task_type == 'detection':\n",
    "            self.training_history['mIoU'].append(0)\n",
    "            self.training_history['mAP'].append(best_metric * 100)\n",
    "            self.training_history['Top1_acc'].append(0)\n",
    "        elif task_type == 'classification':\n",
    "            self.training_history['mIoU'].append(0)\n",
    "            self.training_history['mAP'].append(0)\n",
    "            self.training_history['Top1_acc'].append(best_metric)\n",
    "        \n",
    "        # Initialize EWC\n",
    "        try:\n",
    "            print(\"Computing Fisher information for EWC...\")\n",
    "            importance = 800\n",
    "            ewc = EnhancedEWC(self.model, train_loader, task_type=task_type, importance=importance)\n",
    "            self.ewc_tasks.append(ewc)\n",
    "            print(f\"EWC initialized successfully, task {self.tasks_completed + 1}\")\n",
    "        except Exception as e:\n",
    "            print(f\"EWC initialization failed: {e}\")\n",
    "        \n",
    "        self.tasks_completed += 1\n",
    "        return best_metric\n",
    "    \n",
    "    def evaluate(self, val_loader, task_type):\n",
    "        \"\"\"Evaluate model performance - Improved version\"\"\"\n",
    "        self.model.eval()\n",
    "        total_metric = 0\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "        \n",
    "        # Data collection for mAP computation\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        max_eval_batches = min(len(val_loader), 30)  # Limit evaluation batch count\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                if batch_idx >= max_eval_batches:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    output = self.model(data, task=task_type)\n",
    "                    \n",
    "                    if task_type == 'classification':\n",
    "                        loss = F.cross_entropy(output, target)\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        correct = (predicted == target).sum().item()\n",
    "                        total_metric += correct\n",
    "                        num_samples += target.size(0)\n",
    "                        \n",
    "                    elif task_type == 'segmentation':\n",
    "                        if target.dim() == 4 and target.size(1) == 1:\n",
    "                            target = target.squeeze(1)\n",
    "                        if output.dim() == 4 and output.size(1) == 1:\n",
    "                            output = output.squeeze(1)\n",
    "                        \n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        pred_prob = torch.sigmoid(output)\n",
    "                        intersection = (pred_prob * target).sum()\n",
    "                        union = pred_prob.sum() + target.sum()\n",
    "                        dice_loss = 1 - (2 * intersection + 1) / (union + 1)\n",
    "                        loss = bce_loss + dice_loss\n",
    "                        \n",
    "                        for i in range(output.size(0)):\n",
    "                            iou = self.compute_iou(output[i:i+1], target[i:i+1])\n",
    "                            total_metric += iou\n",
    "                            num_samples += 1\n",
    "                            \n",
    "                    elif task_type == 'detection':\n",
    "                        focal_loss = self.focal_loss(output, target.float())\n",
    "                        bce_loss = F.binary_cross_entropy_with_logits(output, target.float())\n",
    "                        loss = 0.6 * focal_loss + 0.4 * bce_loss\n",
    "                        \n",
    "                        # Collect predictions and true labels for mAP computation\n",
    "                        pred_probs = torch.sigmoid(output).cpu().numpy()\n",
    "                        target_np = target.cpu().numpy()\n",
    "                        \n",
    "                        all_predictions.extend(pred_probs)\n",
    "                        all_targets.extend(target_np)\n",
    "                        \n",
    "                        num_samples += output.size(0)\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Evaluation batch {batch_idx} error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if num_samples == 0:\n",
    "            print(\"Number of evaluation samples is 0\")\n",
    "            return 0.0, 1.0\n",
    "        \n",
    "        avg_loss = total_loss / max_eval_batches if max_eval_batches > 0 else 1.0\n",
    "        \n",
    "        if task_type == 'classification':\n",
    "            accuracy = 100.0 * total_metric / num_samples\n",
    "            print(f\"Classification evaluation: {total_metric}/{num_samples} correct, accuracy: {accuracy:.2f}%\")\n",
    "            return accuracy, avg_loss\n",
    "        elif task_type == 'detection':\n",
    "            if all_predictions and all_targets:\n",
    "                all_predictions = np.array(all_predictions)\n",
    "                all_targets = np.array(all_targets)\n",
    "                map_score = compute_map(all_predictions, all_targets, num_classes=80)\n",
    "                print(f\"Detection evaluation: mAP = {map_score:.4f}\")\n",
    "                return map_score, avg_loss\n",
    "            else:\n",
    "                print(\"Insufficient detection evaluation data\")\n",
    "                return 0.0, avg_loss\n",
    "        else:  # segmentation\n",
    "            avg_iou = total_metric / num_samples\n",
    "            print(f\"Segmentation evaluation: Average IoU = {avg_iou:.4f}\")\n",
    "            return avg_iou, avg_loss\n",
    "    \n",
    "    def evaluate_all_tasks(self, data_loaders):\n",
    "        \"\"\"Evaluate all tasks\"\"\"\n",
    "        print(\"\\n=== Evaluating All Tasks ===\")\n",
    "        \n",
    "        # VOC Segmentation\n",
    "        try:\n",
    "            voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "            voc_metric, _ = self.evaluate(voc_val_loader, 'segmentation')\n",
    "            print(f\"VOC segmentation mIoU: {voc_metric * 100:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"VOC evaluation error: {e}\")\n",
    "            voc_metric = 0\n",
    "        \n",
    "        # COCO Detection\n",
    "        try:\n",
    "            coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "            coco_metric, _ = self.evaluate(coco_val_loader, 'detection')\n",
    "            print(f\"COCO detection mAP: {coco_metric * 100:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"COCO evaluation error: {e}\")\n",
    "            coco_metric = 0\n",
    "        \n",
    "        # ImageNet Classification\n",
    "        try:\n",
    "            imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "            imagenet_metric, _ = self.evaluate(imagenet_val_loader, 'classification')\n",
    "            print(f\"ImageNet classification Top-1: {imagenet_metric:.2f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet evaluation error: {e}\")\n",
    "            imagenet_metric = 0\n",
    "        \n",
    "        return {\n",
    "            'mIoU': voc_metric * 100,\n",
    "            'mAP': coco_metric * 100,\n",
    "            'Top1_acc': imagenet_metric\n",
    "        }\n",
    "    \n",
    "    def check_forgetting_criterion(self, final_metrics, base_metrics):\n",
    "        \"\"\"Check forgetting criterion\"\"\"\n",
    "        current_miou = final_metrics.get('mIoU', 0)\n",
    "        current_map = final_metrics.get('mAP', 0)\n",
    "        current_top1 = final_metrics.get('Top1_acc', 0)\n",
    "        \n",
    "        miou_ok = current_miou >= (base_metrics.get('mIoU', 0) - 5)\n",
    "        map_ok = current_map >= (base_metrics.get('mAP', 0) - 5)\n",
    "        top1_ok = current_top1 >= (base_metrics.get('Top1_acc', 0) - 5)\n",
    "        \n",
    "        print(f\"\\nForgetting criterion check:\")\n",
    "        print(f\"mIoU: {current_miou:.2f}% (≥ {base_metrics.get('mIoU', 0) - 5:.2f}%) - {'Passed' if miou_ok else 'Failed'}\")\n",
    "        print(f\"mAP: {current_map:.2f}% (≥ {base_metrics.get('mAP', 0) - 5:.2f}%) - {'Passed' if map_ok else 'Failed'}\")\n",
    "        print(f\"Top-1: {current_top1:.2f}% (≥ {base_metrics.get('Top1_acc', 0) - 5:.2f}%) - {'Passed' if top1_ok else 'Failed'}\")\n",
    "        \n",
    "        return miou_ok and map_ok and top1_ok\n",
    "    \n",
    "    def plot_loss_curves(self, save_path='balanced_training_losses.png'):\n",
    "        \"\"\"Plot loss curves\"\"\"\n",
    "        if not self.loss_history['stage_names']:\n",
    "            print(\"No loss history to plot\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            num_stages = len(self.loss_history['stage_names'])\n",
    "            fig, axes = plt.subplots(1, num_stages, figsize=(5*num_stages, 4))\n",
    "            if num_stages == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, stage_name in enumerate(self.loss_history['stage_names']):\n",
    "                if i < len(self.loss_history['train_losses']):\n",
    "                    train_losses = self.loss_history['train_losses'][i]\n",
    "                    val_losses = self.loss_history['val_losses'][i]\n",
    "                    epochs = range(1, len(train_losses) + 1)\n",
    "                    \n",
    "                    axes[i].plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "                    axes[i].plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "                    axes[i].set_xlabel('Epoch')\n",
    "                    axes[i].set_ylabel('Loss')\n",
    "                    axes[i].set_title(f'{stage_name}')\n",
    "                    axes[i].legend()\n",
    "                    axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"Loss curves saved to: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting loss curves: {e}\")\n",
    "\n",
    "def get_improved_transforms():\n",
    "    \"\"\"Get improved data transforms - Fixed randomness\"\"\"\n",
    "    # Use fixed random seed to ensure consistency in data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(0.3),  # Reduce randomness\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.02),  # Reduce variation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    seg_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform, seg_transform\n",
    "\n",
    "def create_data_loaders():\n",
    "    \"\"\"Create data loaders\"\"\"\n",
    "    \n",
    "    train_transform, val_transform, seg_transform = get_improved_transforms()\n",
    "    \n",
    "    print(\"Checking dataset paths...\")\n",
    "    \n",
    "    # VOC segmentation dataset\n",
    "    voc_json_path = './VOC_subset/train_list.json'\n",
    "    voc_base_dir = './VOC_subset'\n",
    "    if os.path.exists(voc_json_path):\n",
    "        print(f\"Found VOC JSON: {voc_json_path}\")\n",
    "        voc_train_dataset = VOCSegmentationDataset(\n",
    "            json_file=voc_json_path,\n",
    "            base_dir=voc_base_dir,\n",
    "            transform=train_transform,\n",
    "            seg_transform=seg_transform\n",
    "        )\n",
    "        voc_val_dataset = VOCSegmentationDataset(\n",
    "            json_file=voc_json_path,\n",
    "            base_dir=voc_base_dir,\n",
    "            transform=val_transform,\n",
    "            seg_transform=seg_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"VOC JSON not found: {voc_json_path}\")\n",
    "        print(\"Creating dummy VOC dataset...\")\n",
    "        # Create fixed dummy data\n",
    "        voc_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), torch.ones(50, 1, 224, 224) * 0.5\n",
    "        )\n",
    "        voc_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), torch.ones(20, 1, 224, 224) * 0.5\n",
    "        )\n",
    "    \n",
    "    # COCO detection dataset\n",
    "    coco_train_json = './coco_subset/COCO_train.json'\n",
    "    coco_val_json = './coco_subset/COCO_val.json'\n",
    "    coco_train_dir = './coco_subset/train'\n",
    "    coco_val_dir = './coco_subset/val'\n",
    "    \n",
    "    if os.path.exists(coco_train_json) and os.path.exists(coco_train_dir):\n",
    "        print(f\"Found COCO training set: {coco_train_json} and {coco_train_dir}\")\n",
    "        coco_train_dataset = COCODataset(\n",
    "            json_file=coco_train_json,\n",
    "            img_dir=coco_train_dir,\n",
    "            transform=train_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"COCO training set not found: {coco_train_json} or {coco_train_dir}\")\n",
    "        print(\"Creating dummy COCO training dataset...\")\n",
    "        # Create fixed dummy data\n",
    "        fake_targets = torch.zeros(50, 80)\n",
    "        for i in range(50):\n",
    "            fake_targets[i, i % 80] = 1.0  # Each sample has one fixed label\n",
    "        coco_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), fake_targets\n",
    "        )\n",
    "    \n",
    "    if os.path.exists(coco_val_json) and os.path.exists(coco_val_dir):\n",
    "        print(f\"Found COCO validation set: {coco_val_json} and {coco_val_dir}\")\n",
    "        coco_val_dataset = COCODataset(\n",
    "            json_file=coco_val_json,\n",
    "            img_dir=coco_val_dir,\n",
    "            transform=val_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"COCO validation set not found: {coco_val_json} or {coco_val_dir}\")\n",
    "        print(\"Creating dummy COCO validation dataset...\")\n",
    "        fake_targets = torch.zeros(20, 80)\n",
    "        for i in range(20):\n",
    "            fake_targets[i, i % 80] = 1.0\n",
    "        coco_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), fake_targets\n",
    "        )\n",
    "    \n",
    "    # ImageNet classification dataset\n",
    "    imagenet_train_txt = './imagenetv2_subset/imagenetv2_train.txt'\n",
    "    imagenet_val_txt = './imagenetv2_subset/imagenetv2_val.txt'\n",
    "    imagenet_img_dir = './imagenetv2_subset/imagenetv2'\n",
    "    \n",
    "    if os.path.exists(imagenet_train_txt) and os.path.exists(imagenet_img_dir):\n",
    "        print(f\"Found ImageNet training set: {imagenet_train_txt} and {imagenet_img_dir}\")\n",
    "        imagenet_train_dataset = ImageNetDataset(\n",
    "            txt_file=imagenet_train_txt,\n",
    "            img_dir=imagenet_img_dir,\n",
    "            transform=train_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"ImageNet training set not found: {imagenet_train_txt} or {imagenet_img_dir}\")\n",
    "        print(\"Creating dummy ImageNet training dataset...\")\n",
    "        # Create fixed dummy data with 30 classes\n",
    "        fake_labels = torch.tensor([i % 30 for i in range(50)])\n",
    "        imagenet_train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(50, 3, 224, 224), fake_labels\n",
    "        )\n",
    "        \n",
    "    if os.path.exists(imagenet_val_txt) and os.path.exists(imagenet_img_dir):\n",
    "        print(f\"Found ImageNet validation set: {imagenet_val_txt} and {imagenet_img_dir}\")\n",
    "        imagenet_val_dataset = ImageNetDataset(\n",
    "            txt_file=imagenet_val_txt,\n",
    "            img_dir=imagenet_img_dir,\n",
    "            transform=val_transform\n",
    "        )\n",
    "    else:\n",
    "        print(f\"ImageNet validation set not found: {imagenet_val_txt} or {imagenet_img_dir}\")\n",
    "        print(\"Creating dummy ImageNet validation dataset...\")\n",
    "        fake_labels = torch.tensor([i % 30 for i in range(20)])\n",
    "        imagenet_val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.randn(20, 3, 224, 224), fake_labels\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Create data loaders\n",
    "    batch_size = 8  # Reduce batch size to save memory\n",
    "    \n",
    "    # Set fixed random seed to ensure DataLoader consistency\n",
    "    def worker_init_fn(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "    \n",
    "    try:\n",
    "        voc_train_loader = DataLoader(\n",
    "            voc_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        voc_val_loader = DataLoader(\n",
    "            voc_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        coco_train_loader = DataLoader(\n",
    "            coco_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        coco_val_loader = DataLoader(\n",
    "            coco_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        imagenet_train_loader = DataLoader(\n",
    "            imagenet_train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        imagenet_val_loader = DataLoader(\n",
    "            imagenet_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "            num_workers=0, worker_init_fn=worker_init_fn\n",
    "        )\n",
    "        \n",
    "        print(\"All data loaders created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating data loaders: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'voc': (voc_train_loader, voc_val_loader),\n",
    "        'coco': (coco_train_loader, coco_val_loader),\n",
    "        'imagenet': (imagenet_train_loader, imagenet_val_loader)\n",
    "    }\n",
    "\n",
    "def test_balanced_model():\n",
    "    \"\"\"Test balanced model architecture\"\"\"\n",
    "    print(\"Testing balanced model architecture...\")\n",
    "    \n",
    "    try:\n",
    "        model = BalancedMultiTaskModel(num_classes_det=80, num_classes_cls=1000)\n",
    "        model.eval()\n",
    "        \n",
    "        batch_size = 4\n",
    "        fake_images = torch.randn(batch_size, 3, 224, 224)\n",
    "        \n",
    "        print(f\"Input shape: {fake_images.shape}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            det_output = model(fake_images, task='detection')\n",
    "            seg_output = model(fake_images, task='segmentation')\n",
    "            cls_output = model(fake_images, task='classification')\n",
    "            \n",
    "            print(f\"Detection output shape: {det_output.shape}\")\n",
    "            print(f\"Segmentation output shape: {seg_output.shape}\")\n",
    "            print(f\"Classification output shape: {cls_output.shape}\")\n",
    "        \n",
    "        print(\"Balanced model architecture test completed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Model test failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def test_single_batch(data_loaders):\n",
    "    \"\"\"Test single batch loading\"\"\"\n",
    "    print(\"Testing single batch loading...\")\n",
    "    \n",
    "    if data_loaders is None:\n",
    "        print(\"Data loaders unavailable\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test VOC loader\n",
    "        print(\"Testing VOC loader...\")\n",
    "        voc_train_loader, _ = data_loaders['voc']\n",
    "        try:\n",
    "            batch = next(iter(voc_train_loader))\n",
    "            print(f\"VOC batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"VOC batch failed: {e}\")\n",
    "        \n",
    "        # Test COCO loader\n",
    "        print(\"Testing COCO loader...\")\n",
    "        coco_train_loader, _ = data_loaders['coco']\n",
    "        try:\n",
    "            batch = next(iter(coco_train_loader))\n",
    "            print(f\"COCO batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "            print(f\"COCO target range: [{batch[1].min():.2f}, {batch[1].max():.2f}]\")\n",
    "            print(f\"COCO target type: {batch[1].dtype}\")\n",
    "        except Exception as e:\n",
    "            print(f\"COCO batch failed: {e}\")\n",
    "        \n",
    "        # Test ImageNet loader\n",
    "        print(\"Testing ImageNet loader...\")\n",
    "        imagenet_train_loader, _ = data_loaders['imagenet']\n",
    "        try:\n",
    "            batch = next(iter(imagenet_train_loader))\n",
    "            print(f\"ImageNet batch loaded successfully: {batch[0].shape}, {batch[1].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ImageNet batch failed: {e}\")\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"test_single_batch error: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    \n",
    "    # First set random seed\n",
    "    set_random_seed(42)\n",
    "    # Check CUDA availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    else:\n",
    "        print(\"CUDA unavailable, using CPU\")\n",
    "    \n",
    "    # Test model architecture\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Testing Model Architecture\")\n",
    "    print(\"=\"*50)\n",
    "    if not test_balanced_model():\n",
    "        print(\"Model test failed, exiting...\")\n",
    "        return None\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Creating Data Loaders\")\n",
    "    print(\"=\"*50)\n",
    "    data_loaders = create_data_loaders()\n",
    "    if data_loaders is None:\n",
    "        print(\"Failed to create data loaders, exiting...\")\n",
    "        return None\n",
    "    \n",
    "    # Test data loading\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Testing Data Loading\")\n",
    "    print(\"=\"*50)\n",
    "    if not test_single_batch(data_loaders):\n",
    "        print(\"Data loading test failed, but continuing execution...\")\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Initializing Model\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        model = BalancedMultiTaskModel(num_classes_det=80, num_classes_cls=1000)\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "        else:\n",
    "            print(\"Model using CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model initialization failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Initialize learner\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Initializing Learner\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        learner = BalancedContinualLearner(model, learning_rate=0.0002)\n",
    "        print(\"Balanced continual learner initialization completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Learner initialization failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Stage 1: VOC Segmentation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 1: VOC Segmentation Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        voc_train_loader, voc_val_loader = data_loaders['voc']\n",
    "        miou_base = learner.train_stage(voc_train_loader, voc_val_loader, \n",
    "                                        'segmentation', num_epochs=20, stage_name=\"VOC segmentation\")\n",
    "        print(f\"VOC segmentation baseline mIoU: {miou_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 1\n",
    "    print(\"\\n--- Evaluation after Stage 1 ---\")\n",
    "    try:\n",
    "        stage1_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 evaluation error: {e}\")\n",
    "        stage1_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Stage 2: COCO Detection\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 2: COCO Detection Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        coco_train_loader, coco_val_loader = data_loaders['coco']\n",
    "        map_base = learner.train_stage(coco_train_loader, coco_val_loader, \n",
    "                                        'detection', num_epochs=25, stage_name=\"COCO detection\")\n",
    "        print(f\"COCO detection baseline mAP: {map_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 2 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 2\n",
    "    print(\"\\n--- Evaluation after Stage 2 ---\")\n",
    "    try:\n",
    "        stage2_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 2 evaluation error: {e}\")\n",
    "        stage2_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Stage 3: ImageNet Classification\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Stage 3: ImageNet Classification Training\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        imagenet_train_loader, imagenet_val_loader = data_loaders['imagenet']\n",
    "        top1_base = learner.train_stage(imagenet_train_loader, imagenet_val_loader, \n",
    "                                        'classification', num_epochs=20, stage_name=\"ImageNet classification\")\n",
    "        print(f\"ImageNet classification baseline Top-1: {top1_base:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 3 failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # Evaluation after Stage 3\n",
    "    print(\"\\n--- Evaluation after Stage 3 (before fine-tuning) ---\")\n",
    "    try:\n",
    "        pre_finetune_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Pre-fine-tuning evaluation error: {e}\")\n",
    "        pre_finetune_metrics = {'mIoU': 0, 'mAP': 0, 'Top1_acc': 0}\n",
    "    \n",
    "    # Set target metrics (allow 5% drop)\n",
    "    target_metrics = {\n",
    "        'mIoU': miou_base * 100 - 5,\n",
    "        'mAP': map_base * 100 - 5,\n",
    "        'Top1_acc': top1_base - 5\n",
    "    }\n",
    "\n",
    "    print(f\"\\nTarget metrics (baseline - 5%):\")\n",
    "    print(f\"mIoU: ≥ {target_metrics['mIoU']:.2f}%\")\n",
    "    print(f\"mAP: ≥ {target_metrics['mAP']:.2f}%\")\n",
    "    print(f\"Top-1: ≥ {target_metrics['Top1_acc']:.2f}%\")\n",
    "    \n",
    "    # Check if balanced multi-task fine-tuning is needed\n",
    "    needs_finetuning = (\n",
    "        pre_finetune_metrics['mIoU'] < target_metrics['mIoU'] or\n",
    "        pre_finetune_metrics['mAP'] < target_metrics['mAP'] or\n",
    "        pre_finetune_metrics['Top1_acc'] < target_metrics['Top1_acc']\n",
    "    )\n",
    "    \n",
    "    if needs_finetuning:\n",
    "        print(f\"\\nSome metrics are below target. Starting balanced multi-task fine-tuning...\")\n",
    "        print(f\"Current: mIoU={pre_finetune_metrics['mIoU']:.2f}%, \"\n",
    "              f\"mAP={pre_finetune_metrics['mAP']:.2f}%, \"\n",
    "              f\"Top1={pre_finetune_metrics['Top1_acc']:.2f}%\")\n",
    "        \n",
    "        # Execute balanced multi-task fine-tuning\n",
    "        try:\n",
    "            improved_metrics = learner.balanced_multi_task_fine_tuning(data_loaders, target_metrics)\n",
    "            print(f\"Balanced fine-tuning completed!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fine-tuning failed: {e}\")\n",
    "            traceback.print_exc()\n",
    "            improved_metrics = pre_finetune_metrics\n",
    "    else:\n",
    "        print(f\"All metrics meet target standards. No fine-tuning needed.\")\n",
    "        improved_metrics = pre_finetune_metrics\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Final Results\")\n",
    "    print(\"=\"*50)\n",
    "    try:\n",
    "        final_metrics = learner.evaluate_all_tasks(data_loaders)\n",
    "    except Exception as e:\n",
    "        print(f\"Final evaluation error: {e}\")\n",
    "        final_metrics = improved_metrics\n",
    "    \n",
    "    # Check forgetting criterion\n",
    "    base_metrics = {\n",
    "        'mIoU': miou_base * 100,\n",
    "        'mAP': map_base * 100, \n",
    "        'Top1_acc': top1_base\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        criterion_met = learner.check_forgetting_criterion(final_metrics, base_metrics)\n",
    "        print(f\"\\nForgetting criterion satisfied: {'Yes' if criterion_met else 'No'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking forgetting criterion: {e}\")\n",
    "        criterion_met = False\n",
    "    \n",
    "    # Detailed performance analysis\n",
    "    print(f\"\\nDetailed performance analysis:\")\n",
    "    try:\n",
    "        miou_change = final_metrics['mIoU'] - miou_base * 100\n",
    "        map_change = final_metrics['mAP'] - map_base * 100\n",
    "        top1_change = final_metrics['Top1_acc'] - top1_base\n",
    "        \n",
    "        print(f\"VOC mIoU: {final_metrics['mIoU']:.2f}% (baseline: {miou_base * 100:.2f}%, change: {miou_change:+.2f}%)\")\n",
    "        print(f\"COCO mAP: {final_metrics['mAP']:.2f}% (baseline: {map_base * 100:.2f}%, change: {map_change:+.2f}%)\")\n",
    "        print(f\"ImageNet Top-1: {final_metrics['Top1_acc']:.2f}% (baseline: {top1_base:.2f}%, change: {top1_change:+.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Performance analysis error: {e}\")\n",
    "        miou_change = map_change = top1_change = 0\n",
    "    \n",
    "    # Print training history\n",
    "    print(f\"\\nTraining history:\")\n",
    "    try:\n",
    "        for i, stage in enumerate(learner.training_history['stage']):\n",
    "            print(f\"{stage}: mIoU={learner.training_history['mIoU'][i]:.2f}%, \"\n",
    "                    f\"mAP={learner.training_history['mAP'][i]:.2f}%, \"\n",
    "                    f\"Top1={learner.training_history['Top1_acc'][i]:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error printing training history: {e}\")\n",
    "    \n",
    "    # Success criteria check\n",
    "    try:\n",
    "        success_criteria = {\n",
    "            'mIoU_ok': final_metrics['mIoU'] >= (miou_base * 100 - 5),\n",
    "            'mAP_ok': final_metrics['mAP'] >= (map_base * 100 - 5),\n",
    "            'Top1_ok': final_metrics['Top1_acc'] >= (top1_base - 5)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nSuccess criteria:\")\n",
    "        print(f\"mIoU ≥ {miou_base * 100 - 5:.2f}%: {'Passed' if success_criteria['mIoU_ok'] else 'Failed'}\")\n",
    "        print(f\"mAP ≥ {map_base * 100 - 5:.2f}%: {'Passed' if success_criteria['mAP_ok'] else 'Failed'}\")\n",
    "        print(f\"Top-1 ≥ {top1_base - 5:.2f}%: {'Passed' if success_criteria['Top1_ok'] else 'Failed'}\")\n",
    "        \n",
    "        overall_success = all(success_criteria.values())\n",
    "        print(f\"\\nOverall success: {'Passed' if overall_success else 'Failed'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Success criteria check error: {e}\")\n",
    "        overall_success = False\n",
    "        success_criteria = {'mIoU_ok': False, 'mAP_ok': False, 'Top1_ok': False}\n",
    "    \n",
    "    # Performance comparison\n",
    "    print(f\"\\nPerformance comparison:\")\n",
    "    try:\n",
    "        print(f\"{'Metric':<15} {'Stage1':<10} {'Stage2':<10} {'Stage3':<10} {'Final':<10} {'Change':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        print(f\"{'mIoU (%)':<15} {stage1_metrics['mIoU']:<10.2f} {stage2_metrics['mIoU']:<10.2f} {pre_finetune_metrics['mIoU']:<10.2f} {final_metrics['mIoU']:<10.2f} {miou_change:<+10.2f}\")\n",
    "        print(f\"{'mAP (%)':<15} {stage1_metrics['mAP']:<10.2f} {stage2_metrics['mAP']:<10.2f} {pre_finetune_metrics['mAP']:<10.2f} {final_metrics['mAP']:<10.2f} {map_change:<+10.2f}\")\n",
    "        print(f\"{'Top-1 (%)':<15} {stage1_metrics['Top1_acc']:<10.2f} {stage2_metrics['Top1_acc']:<10.2f} {pre_finetune_metrics['Top1_acc']:<10.2f} {final_metrics['Top1_acc']:<10.2f} {top1_change:<+10.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Performance comparison error: {e}\")\n",
    "    \n",
    "    \n",
    "    # Plot results\n",
    "    print(\"\\nPlotting training results...\")\n",
    "    try:\n",
    "        learner.plot_loss_curves('balanced_training_losses.png')\n",
    "        print(\"Loss curves saved successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting error: {e}\")\n",
    "    \n",
    "    \n",
    "    # Return results\n",
    "    try:\n",
    "        return {\n",
    "            'final_metrics': final_metrics,\n",
    "            'base_metrics': base_metrics,\n",
    "            'success': overall_success,\n",
    "            'learner': learner,\n",
    "            'stage_progression': {\n",
    "                'stage1': stage1_metrics,\n",
    "                'stage2': stage2_metrics,\n",
    "                'stage3': pre_finetune_metrics,\n",
    "                'final': final_metrics\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating return object: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"Starting balanced multi-task learning...\")\n",
    "    results = main()\n",
    "    if results:\n",
    "        print(\"Training completed successfully!\")\n",
    "        print(f\"\\nFinal summary:\")\n",
    "        print(f\"mIoU: {results['final_metrics']['mIoU']:.2f}%\")\n",
    "        print(f\"mAP: {results['final_metrics']['mAP']:.2f}%\") \n",
    "        print(f\"Top-1: {results['final_metrics']['Top1_acc']:.2f}%\")\n",
    "        print(f\"Overall success: {'Passed' if results['success'] else 'Failed'}\")\n",
    "    else:\n",
    "        print(\"Training failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
